from datetime import datetime
import time
import aiomysql
from ananbot_config import DB_CONFIG
from utils.lybase_utils import LYBase
from utils.string_utils import LZString
from utils.prof import SegTimer
import uuid
import asyncio
import pymysql
from typing import Optional
from lz_memory_cache import MemoryCache
import lz_var
from lz_config import AES_KEY
from utils.aes_crypto import AESCrypto


class AnanBOTPool(LYBase):
    _pool = None
    _pool_lock = asyncio.Lock()  # æ–°å¢ï¼šå¹¶å‘å®‰å…¨
    _acq_sem = asyncio.Semaphore(16)      # æ–°å¢ï¼šæ€»é™æµï¼ˆå‰å°+åå°ï¼‰
    _bg_sem  = asyncio.Semaphore(4)       # æ–°å¢ï¼šåå°å†™å…¥ä¸“ç”¨é™æµ
    _all_tags_grouped_cache = None
    _all_tags_grouped_cache_ts = 0
    _cache_ttl = 300  # ç¼“å­˜æœ‰æ•ˆæ—¶é—´ï¼ˆç§’ï¼‰
    _all_tags_types_cache = None
    _all_tags_types_cache_ts = 0
    _cache_ready = False
    cache = None

    @classmethod
    async def init_pool_old(cls):
        if cls._pool is None:
            async with cls._pool_lock:
                if cls._pool is None:
                    # âœ… å»ºè®®ï¼šåœ¨ DB_CONFIG é‡Œä¹Ÿå¯ç›´æ¥é…è¿™äº›é”®ï¼›è¿™é‡Œåšå…œåº•
                    kwargs = dict(DB_CONFIG)
                    kwargs.setdefault("autocommit", True)
                    kwargs.setdefault("minsize", 1)
                    kwargs.setdefault("maxsize", 10)
                    kwargs.setdefault("connect_timeout", 10)
                    kwargs.setdefault("pool_recycle", 120)  # å…³é”®ï¼š120 ç§’å›æ”¶é™ˆæ—§è¿æ¥
                    kwargs.setdefault("charset", "utf8mb4")

                    cls._pool = await aiomysql.create_pool(**kwargs)
                    print("âœ… MySQL è¿æ¥æ± åˆå§‹åŒ–å®Œæˆï¼ˆautocommit, recycle=120ï¼‰")
            
            if not cls._cache_ready:
                cls.cache = MemoryCache()
                cls._cache_ready = True
            

    @classmethod
    async def init_pool(cls):
        if cls._pool is None:
            async with cls._pool_lock:
                if cls._pool is None:
                    kwargs = dict(DB_CONFIG)
                    kwargs.setdefault("autocommit", True)
                    kwargs.setdefault("minsize", 2)
                    kwargs.setdefault("maxsize", 40)
                    kwargs.setdefault("connect_timeout", 10)
                    kwargs.setdefault("pool_recycle", 110)  # å»ºè®®ç•¥å°äº MySQL wait_timeout
                    kwargs.setdefault("charset", "utf8mb4")

                    delay = 0.3
                    for i in range(4):
                        try:
                            cls._pool = await aiomysql.create_pool(**kwargs)
                            print("âœ… MySQL è¿æ¥æ± åˆå§‹åŒ–å®Œæˆ")
                            break
                        except Exception as e:
                            if i == 3:
                                raise
                            await asyncio.sleep(delay)
                            delay *= 2

            if not cls._cache_ready:
                cls.cache = MemoryCache()
                cls._cache_ready = True



    @classmethod
    async def _reset_pool_old(cls):
        if cls._pool:
            cls._pool.close()
            await cls._pool.wait_closed()
            cls._pool = None

    
    @classmethod
    async def _reset_pool(cls):
        async with cls._pool_lock:
            if cls._pool:
                try:
                    cls._pool.close()
                    # é˜²æ­¢è¢«å¤–å±‚ wait_for å–æ¶ˆï¼Œä¸”é™åˆ¶ç­‰å¾…æ—¶é•¿
                    await asyncio.wait_for(asyncio.shield(cls._pool.wait_closed()), timeout=20)
                except Exception as e:
                    print(f"âš ï¸ wait_closed å¼‚å¸¸(å¿½ç•¥): {e}")
                finally:
                    cls._pool = None



    @classmethod
    async def get_conn_cursor_old(cls):
        # if cls._pool is None:
        #     raise Exception("MySQL è¿æ¥æ± æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ init_pool()")
        try:
            conn = await cls._pool.acquire()
            try:
                await conn.ping()  # âœ… è½»é‡è‡ªæ£€ï¼Œè§¦å‘åº•å±‚é‡è¿
            except Exception:
                # è¿æ¥å·²åï¼šé‡å»ºè¿æ¥æ± å†å–
                await cls._reset_pool()
                await cls.init_pool()
                conn = await cls._pool.acquire()
                await conn.ping()
            cursor = await conn.cursor(aiomysql.DictCursor)
            return conn, cursor
        except Exception as e:
            # æœ€åå…œåº•ï¼šå½»åº•é‡ç½®å†è¯•ä¸€æ¬¡
            await cls._reset_pool()
            await cls.init_pool()
            conn = await cls._pool.acquire()
            cursor = await conn.cursor(aiomysql.DictCursor)
            return conn, cursor
    
    @classmethod
    async def get_conn_cursor(cls):
        if cls._pool is None:
            await cls.init_pool()
        # â˜† å…³é”®ï¼šç»Ÿä¸€ç»ç”±æ€»ä¿¡å·é‡é™æµ
        async with cls._acq_sem:
            try:
                conn = await asyncio.wait_for(cls._pool.acquire(), timeout=20)
                try:
                    await conn.ping()
                except Exception:
                    await cls._reset_pool()
                    await cls.init_pool()
                    conn = await asyncio.wait_for(cls._pool.acquire(), timeout=20)
                    await conn.ping()
                cursor = await conn.cursor(aiomysql.DictCursor)
                return conn, cursor
            except Exception:
                await cls._reset_pool()
                await cls.init_pool()
                conn = await asyncio.wait_for(cls._pool.acquire(), timeout=20)
                cursor = await conn.cursor(aiomysql.DictCursor)
                return conn, cursor


    @classmethod
    async def release(cls, conn, cursor):
        try:
            await cursor.close()
        except Exception as e:
            print(f"âš ï¸ å…³é—­ cursor æ—¶å¤±è´¥: {e}")

        try:
            # âœ… å…³é”®é˜²å‘†ï¼šé¿å…é‡å¤é‡Šæ”¾æˆ–éæ³•è¿æ¥é‡Šæ”¾
            if hasattr(cls._pool, "_used") and conn in cls._pool._used:
                cls._pool.release(conn)
        except Exception as e:
            print(f"âš ï¸ é‡Šæ”¾è¿æ¥å¤±è´¥: {e}")



    @classmethod
    async def is_media_published(cls, file_type, file_unique_id):
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(f"SELECT kc_id FROM `{file_type}` WHERE file_unique_id=%s", (file_unique_id,))
            row = await cur.fetchone()
            return (row is not None, row["kc_id"] if row else None)
        finally:
            await cls.release(conn, cur)


    @classmethod
    def _is_transient_mysql_error(cls, e: BaseException) -> bool:
        # 2006: MySQL server has gone away
        # 2013: Lost connection to MySQL server during query
        # 104 : Connection reset by peerï¼ˆéƒ¨åˆ†å°è£…åœ¨ args[0]ï¼‰
        codes = {2006, 2013, 104}
        try:
            code = getattr(e, "args", [None])[0]
            return code in codes
        except Exception:
            return False

    @classmethod
    async def upsert_media(cls, file_type, data: dict):
        if file_type == 'v':
            file_type = 'video'
        elif file_type == 'p':
            file_type = 'photo'
        elif file_type == 'd':
            file_type = 'document'
        elif file_type == 'n':
            file_type = 'animation'



        if file_type != "video":
            data.pop("duration", None)
        if file_type == "document":
            data.pop("width", None)
            data.pop("height", None)

        keys = list(data.keys())
        placeholders = ', '.join(['%s'] * len(keys))
        columns = ', '.join(f"`{k}`" for k in keys)
        updates = ', '.join(f"`{k}`=VALUES(`{k}`)" for k in keys if k != "create_time")
        sql = f"""
            INSERT INTO `{file_type}` ({columns})
            VALUES ({placeholders})
            ON DUPLICATE KEY UPDATE {updates}
        """
        params = [data[k] for k in keys]

        # âœ… å¸¦é‡è¯•ï¼ˆæŒ‡æ•°é€€é¿ï¼š0.2, 0.4ï¼‰
        delay = 0.2
        attempts = 3
        for i in range(attempts):
            conn, cur = await cls.get_conn_cursor()
            try:
                await cur.execute(sql, params)
                return
            except (pymysql.err.OperationalError, aiomysql.OperationalError, ConnectionResetError) as e:
                if not cls._is_transient_mysql_error(e) or i == attempts - 1:
                    raise
                # è¿æ¥å¯èƒ½å·²åï¼Œé‡ç½®è¿æ¥æ±  + é€€é¿åé‡è¯•
                await cls._reset_pool()
                await asyncio.sleep(delay)
                delay *= 2
            finally:
                await cls.release(conn, cur)



    @classmethod
    async def upsert_media_bulk(cls, rows: list[dict], *, batch_size: int = 200, show_sql: bool = False):
        """
        æ‰¹é‡ upsert å„åª’ä½“è¡¨ï¼ˆvideo/document/photo/animationï¼‰ã€‚
        rows æ¯é¡¹æ ¼å¼ç±»ä¼¼ï¼š
        {
            "file_type": "video",
            "file_unique_id": "AgAD...",
           
            "file_size": 123456,
            "duration": 5,
            "width": 640,
            "height": 360,
            "file_name": "xxx.mp4",
            "create_time": datetime.now()
        }
        """
        if not rows:
            print("âš ï¸ upsert_media_bulk: ç©ºåˆ—è¡¨ï¼Œè·³è¿‡ã€‚")
            return 0

        await cls.init_pool()
        inserted_total = 0

        # æŒ‰ file_type åˆ†ç»„ï¼švideo/document/photo/animation
        groups = {}
        for r in rows:
            ft = r.get("file_type")
            if ft in ("v", "video"): ft = "video"
            elif ft in ("d", "document"): ft = "document"
            elif ft in ("p", "photo"): ft = "photo"
            elif ft in ("n", "animation"): ft = "animation"
            else:
                continue
            groups.setdefault(ft, []).append(r)

        conn, cur = await cls.get_conn_cursor()
        try:
            for ft, items in groups.items():
                if not items:
                    continue

                # æ¸…ç†å­—æ®µï¼šä¸åŒç±»å‹å­—æ®µä¸åŒ
                clean_rows = []
                for item in items:
                    d = dict(item)
                    d.pop("file_type", None)  # è¡¨åç”¨ï¼Œä¸å…¥åˆ—
                    d.pop("file_id", None)    # â— å…³é”®ï¼šåª’ä½“è¡¨ä¸å­˜ file_id
                    if ft != "video":
                        d.pop("duration", None)
                    if ft == "document":
                        d.pop("width", None)
                        d.pop("height", None)
                    if ft == "photo":
                        d.pop("mime_type", None)
                    d['create_time'] = d.get('create_time') or datetime.now()
                    clean_rows.append(d)
                # print(f"clean_rows=>{clean_rows}")
                # å–å‡ºæ‰€æœ‰åˆ—å
                keys = sorted({k for r in clean_rows for k in r.keys()})
                # åˆ é™¤ file_type (è¡¨åç”¨ï¼Œä¸å…¥åˆ—)
                if "file_type" in keys:
                    keys.remove("file_type")

                placeholders = ",".join(["%s"] * len(keys))
                columns = ",".join(f"`{k}`" for k in keys)
                updates = ",".join(f"`{k}`=VALUES(`{k}`)" for k in keys if k != "create_time")

                base_sql = f"""
                    INSERT INTO `{ft}` ({columns})
                    VALUES {{values}}
                    ON DUPLICATE KEY UPDATE {updates}
                """

                # åˆ†æ‰¹
                from math import ceil
                total_batches = ceil(len(clean_rows) / batch_size)
                for b in range(total_batches):
                    chunk = clean_rows[b*batch_size:(b+1)*batch_size]
                    vals = []
                    for r in chunk:
                        vals.extend([r.get(k) for k in keys])

                    value_block = ",".join(["(" + placeholders + ")"] * len(chunk))
                    sql = base_sql.format(values=value_block)

                    # ğŸ§© è°ƒè¯•æ¨¡å¼ï¼šæ‰“å°å®Œæ•´ SQLï¼ˆå«å€¼ï¼‰
                    if show_sql:
                        def fmt(v):
                            if v is None: return "NULL"
                            elif isinstance(v, (int, float)): return str(v)
                            elif isinstance(v, datetime): return f"'{v.strftime('%Y-%m-%d %H:%M:%S')}'"
                            else: return f"'{str(v).replace("'", "''")}'"
                        formatted_chunks = [
                            "(" + ",".join(fmt(r.get(k)) for k in keys) + ")" for r in chunk
                        ]
                        print(f"\nğŸ“¦ [Table {ft}] æ‰¹æ¬¡ {b+1}/{total_batches} å®é™…æ‰§è¡Œ SQLï¼š")
                        print(base_sql.format(values=",".join(formatted_chunks)))

                    await cur.execute(sql, vals)
                    inserted_total += cur.rowcount
                    if show_sql:
                        print(f"âœ… [{ft}] æ‰¹æ¬¡ {b+1} å®Œæˆï¼Œå½±å“è¡Œæ•°ï¼š{cur.rowcount}")

            await conn.commit()
            print(f"âœ… upsert_media_bulk å®Œæˆï¼Œæ€»å½±å“è¡Œæ•°ï¼š{inserted_total}")
        except Exception as e:
            await conn.rollback()
            print(f"âŒ upsert_media_bulk å¤±è´¥: {e}")
            raise
        finally:
            await cls.release(conn, cur)

        return inserted_total


    @classmethod
    async def insert_file_extension(cls, file_type, file_unique_id, file_id, bot_username, user_id):
        # åå°å†™å…¥è·¯å¾„ä½¿ç”¨æ›´å°å¹¶å‘ï¼Œé¿å…äº‰æŠ¢
        async with cls._bg_sem:
            conn, cur = await cls.get_conn_cursor()
            try:
                await cur.execute(
                    """INSERT IGNORE INTO file_extension 
                    (file_type, file_unique_id, file_id, bot, user_id, create_time)
                    VALUES (%s, %s, %s, %s, %s, %s)""",
                    (file_type, file_unique_id, file_id, bot_username, user_id, datetime.now())
                )
            finally:
                await cls.release(conn, cur)


    # in ananbot_utils.py (AnanBOTPool class)
    @classmethod
    async def insert_file_extension_bulk(cls, rows: list[dict], *, batch_size: int = 300):
        """
        rows: [{file_type, file_unique_id, file_id, bot_username|bot, user_id, create_time?}, ...]
        æ‰¹é‡å†™å…¥ file_extensionï¼›åˆ†æ‰¹å¤šå€¼ INSERT + ON DUPLICATE KEY UPDATE
        """
        if not rows:
            return 0

        await cls.init_pool()
        inserted_total = 0

        # é¢„å¤„ç†/æ¸…æ´—å­—æ®µå
        normed = []
        now = datetime.now()
        for r in rows:
            ft   = r.get("file_type")
            fuid = r.get("file_unique_id")
            fid  = r.get("file_id")
            bot  = r.get("bot") or r.get("bot_username")
            uid  = r.get("user_id")
            if not (ft and fuid and fid and bot):
                continue
            normed.append((
                ft, fuid, fid, bot, uid, r.get("create_time") or now
            ))

        if not normed:
            return 0

        sql = """
            INSERT INTO file_extension
                (file_type, file_unique_id, file_id, bot, user_id, create_time)
            VALUES
                {values}
            ON DUPLICATE KEY UPDATE
                -- è‹¥ unique å†²çªï¼ˆ(file_unique_id,file_id) æˆ– (file_id,bot)ï¼‰ï¼š
                -- ä¿æŒ file_id ä¸å˜ï¼Œå›å†™æœ€æ–° bot/user_id/create_time
                bot        = VALUES(bot),
                user_id    = IFNULL(VALUES(user_id), user_id),
                create_time= VALUES(create_time)
        """

        # åˆ†æ‰¹æ‰§è¡Œï¼Œæ§åˆ¶å•æ¬¡ SQL ä½“é‡
        from math import ceil
        total_batches = ceil(len(normed) / batch_size)

        conn, cur = await cls.get_conn_cursor()
        try:
            for i in range(total_batches):
                chunk = normed[i*batch_size:(i+1)*batch_size]
                # ç»„è£…å¤šå€¼å ä½
                placeholders = ",".join(["(%s,%s,%s,%s,%s,%s)"] * len(chunk))
                flat_params = []
                for tup in chunk:
                    flat_params.extend(tup)

                await cur.execute(sql.format(values=placeholders), flat_params)
                inserted_total += cur.rowcount  # æ³¨æ„ï¼šåŒ…å«â€œæ’å…¥/æ›´æ–°â€çš„å—å½±å“è¡Œè®¡æ•°
                # æ˜¾ç¤ºæ‰§è¡Œçš„sql
               
            await conn.commit()
        except Exception:
            await conn.rollback()
            raise
        finally:
            await cls.release(conn, cur)

        return inserted_total


    @classmethod
    async def insert_file_extension_old(cls, file_type, file_unique_id, file_id, bot_username, user_id):
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                """INSERT IGNORE INTO file_extension 
                   (file_type, file_unique_id, file_id, bot, user_id, create_time)
                   VALUES (%s, %s, %s, %s, %s, %s)""",
                (file_type, file_unique_id, file_id, bot_username, user_id, datetime.now())
            )
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def insert_sora_content_media(cls, file_unique_id, file_type, file_size, duration, user_id, file_id, bot_username):
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                """
                INSERT INTO sora_content
                    (source_id, file_type, file_size, duration, owner_user_id, stage)
                VALUES
                    (%s, %s, %s, %s, %s, 'pending')
                ON DUPLICATE KEY UPDATE
                    file_type     = VALUES(file_type),
                    file_size     = VALUES(file_size),
                    duration      = VALUES(duration),
                    owner_user_id = IF(
                        sora_content.owner_user_id IS NULL OR sora_content.owner_user_id = 0,
                        VALUES(owner_user_id),
                        sora_content.owner_user_id
                    ),        
                    stage         = 'pending'
                """,
                (file_unique_id, file_type, file_size, duration, user_id)
            )
            await cur.execute("SELECT * FROM sora_content WHERE source_id=%s LIMIT 1", (file_unique_id,))
            row = (await cur.fetchone())
            content_id = row["id"]
            
            await cur.execute(
                """
                INSERT INTO sora_media
                    (content_id, source_bot_name, file_id)
                VALUES
                    (%s, %s, %s)
                ON DUPLICATE KEY UPDATE
                    file_id = VALUES(file_id)
                """,
                (content_id, bot_username, file_id)
            )
            return row
        finally:
            await cls.release(conn, cur)

    @classmethod    
    async def upsert_product_thumb(cls, content_id: int, thumb_file_unique_id: str, thumb_file_id: str, bot_username: str):
        """
        æ›´æ–°ç¸®åœ–è³‡è¨Šï¼š
        - sora_content: æ›´æ–° thumb_file_unique_idï¼ˆåƒ…ç•¶è©² content å­˜åœ¨ï¼‰
        - sora_media: ä¾ content_id + source_bot_name åš UPSERTï¼Œæ›´æ–° thumb_file_id

        å›å‚³ï¼šdictï¼ŒåŒ…å«å„æ­¥é©Ÿå—å½±éŸ¿ç­†æ•¸/ç‹€æ…‹
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            content_rows = 0
            print(f"tfud={thumb_file_unique_id} tfid={thumb_file_id} cid={content_id} bot={bot_username}", flush=True)
            if thumb_file_unique_id!="":
                # 1) å˜—è©¦æ›´æ–° sora_contentï¼ˆè‹¥è©² content_id ä¸å­˜åœ¨å‰‡ä¸æœƒæœ‰å½±éŸ¿ï¼‰
                await cur.execute(
                    """
                    UPDATE sora_content
                    SET thumb_file_unique_id = %s
                    WHERE id = %s 
                    """,
                    (thumb_file_unique_id, content_id)
                )
                # æ‰“å°æ‰§è¡Œçš„SQL
                # cur_sql = cur._last_executed
                # print(f"âœ… [X-MEDIA] æ‰§è¡Œçš„ SQL: {cur_sql}", flush=True)

                content_rows = cur.rowcount  # å—å½±éŸ¿ç­†æ•¸ï¼ˆ0 ä»£è¡¨è©² content_id ä¸å­˜åœ¨ï¼‰
                print(f"âœ… [X-MEDIA] æ›´æ–° sora_content ç¸®ç•¥åœ–(thumb_file_unique_id)", flush=True)

            # 2) å° sora_media åš UPSERTï¼ˆä¸å­˜åœ¨å‰‡æ’å…¥ï¼Œå­˜åœ¨å‰‡æ›´æ–° thumb_file_idï¼‰
            # ä¾è³´å”¯ä¸€éµ uniq_content_bot (content_id, source_bot_name)
            print(f"âœ… [X-MEDIA] æ­£åœ¨ UPSERT sora_media ç¸®ç•¥åœ–...", flush=True)
            await cur.execute(
                """
                INSERT INTO sora_media (content_id, source_bot_name, thumb_file_id)
                VALUES (%s, %s, %s)
                ON DUPLICATE KEY UPDATE
                    thumb_file_id = VALUES(thumb_file_id)
                """,
                (content_id, bot_username, thumb_file_id)
            )
            # åœ¨ MariaDB/MySQL ä¸­ï¼ŒON DUPLICATE è§¸ç™¼æ›´æ–°æ™‚ rowcount æœƒæ˜¯ 2ï¼ˆ1 æ’å…¥ã€2 æ›´æ–°çš„æ…£ä¾‹ä¸å®Œå…¨ä¸€è‡´ï¼Œä¾ç‰ˆæœ¬è€Œç•°ï¼‰
            # media_rows = cur.rowcount

            # cur_sql = cur._last_executed
            # print(f"âœ… [X-MEDIA] æ‰§è¡Œçš„ SQL: {cur_sql}", flush=True)

            # print(f"âœ… [X-MEDIA] UPSERT sora_media ç¸®ç•¥åœ–å®Œæˆï¼Œå—å½±éŸ¿ç­†æ•¸ï¼š{media_rows}", flush=True)
            await conn.commit()

            print(f"âœ… [X-MEDIA] ç¸®ç•¥åœ–æ›´æ–°äº‹å‹™å®Œæˆ", flush=True)

            return {
                "sora_content_updated_rows": content_rows,
                # "sora_media_upsert_rowcount": media_rows
            }

        except Exception as e:
            try:
                await conn.rollback()
            except:
                pass
            # è®“ä¸Šå±¤çŸ¥é“ç™¼ç”Ÿäº†ä»€éº¼éŒ¯
            raise
        finally:
            await cls.release(conn, cur)


    @classmethod
    async def update_product_password(cls, content_id: int, password: str, user_id: int = 0, overwrite: int = 0):
        """
        æ›´æ–° sora_content.file_password
        - password: å­—ç¬¦ä¸²ï¼ˆå…è®¸ç©º => æ¸…é™¤å¯†ç ï¼‰
        - overwrite: ä¿ç•™å‚æ•°ç»“æ„ä¸ update_product_content ä¸€è‡´ï¼ˆæš‚æ—¶ä¸éœ€è¦å¤„ç†åª’ä½“è¡¨ï¼‰
        """
        timer = SegTimer("update_product_password", content_id=content_id, overwrite=int(overwrite))

        try:
            await cls.init_pool()
            async with cls._pool.acquire() as conn:
                async with conn.cursor() as cur:
                    timer.lap("acquire_conn_and_cursor")

                    # è¿™é‡Œä¸éœ€è¦åƒ update_product_content é‚£æ ·å¤„ç†åª’ä½“è¡¨ captionï¼Œ
                    # åªéœ€æ›´æ–° sora_content.file_passwordã€‚
                    await cur.execute(
                        """
                        UPDATE sora_content
                           SET file_password = %s,
                               stage         = 'pending'
                         WHERE id = %s
                        """,
                        (password, content_id)
                    )
                    timer.lap("update_sora_content_password")

                await conn.commit()
                timer.lap("commit")

        except Exception as e:
            try:
                await conn.rollback()
            except Exception:
                pass
            print(f"[update_product_password] ERROR: {e}", flush=True)
            raise
        finally:
            timer.end()


    @classmethod
    async def update_bid_thumbnail(cls, file_unique_id: str, thumb_file_unique_id: str, thumb_file_id: str , bot_username: str):
        conn, cur = await cls.get_conn_cursor()
        try:
            sql = (
                "INSERT INTO bid_thumbnail "
                "(file_unique_id, thumb_file_unique_id, bot_name, file_id, confirm_status) "
                "VALUES (%s,%s,%s,%s,%s) "
                "ON DUPLICATE KEY UPDATE "
                "bot_name=VALUES(bot_name), "
                "file_id=VALUES(file_id), "
                "confirm_status=VALUES(confirm_status)"
            )   
            await cur.execute(
                sql,
                (
                    file_unique_id,
                    thumb_file_unique_id,
                    bot_username,
                    thumb_file_id,
                    10
                )
            )
           
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def update_product_price(cls, content_id: str, price: int):
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                "UPDATE product SET price=%s, stage='pending' WHERE content_id=%s",
                (price, content_id)
            )
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def create_product(cls, content_id, name, desc, price, file_type, user_id):
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                """INSERT INTO product 
                   (name, content, price, content_id, file_type, owner_user_id,stage)
                   VALUES (%s, %s, %s, %s, %s, %s, "pending")""",
                (name, desc, price, content_id, file_type, user_id)
            )
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def get_existing_product(cls, content_id: str):
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                "SELECT id,price,content,file_type,bid_status,review_status,anonymous_mode,owner_user_id FROM product WHERE content_id = %s LIMIT 1",
                (content_id,)
            )
            row = await cur.fetchone()
            return {"id": row["id"], "price": row["price"],"content": row['content'],"file_type":row['file_type'],"anonymous_mode":row['anonymous_mode'],"review_status":row['review_status'],"owner_user_id":row['owner_user_id']} if row else None
        finally:
            await cls.release(conn, cur)


    @classmethod
    async def get_or_create_pending_product(cls, user_id: int) -> int:
        """
        è‹¥è¯¥ user å·²æœ‰ review_status=0/1 çš„äº§å“ â†’ ç›´æ¥å›ä¼  product.content_id
        è‹¥æ—  â†’ æ–°å»º sora_content(file_type='album') å†å»º productï¼Œå›ä¼  content_id
        """
        await cls.init_pool()
        conn, cur = await cls.get_conn_cursor()
        try:
            # 1) æŸ¥æ‰¾æ˜¯å¦å·²æœ‰æœªå®Œæˆå•†å“ï¼ˆreview_status=0 or 1ï¼‰
            await cur.execute(
                """
                SELECT content_id
                  FROM product
                 WHERE owner_user_id=%s
                   AND review_status IN (0,1)
                 LIMIT 1
                """,
                (user_id,)
            )
            row = await cur.fetchone()
            if row:
                # å·²å­˜åœ¨æœªå®Œæˆå•†å“ â†’ ç›´æ¥å›ä¼ 
                return int(row["content_id"])

            # 2) æ²¡æœ‰ â†’ æ–°å»º sora_content
            # ç”Ÿæˆéšæœºä¸é‡å¤ source_idï¼ˆé•¿åº¦ 36ï¼‰
            source_id = uuid.uuid4().hex
            # åªå–å‰28ä¸ªå­—ç¬¦ï¼Œé¿å…è¿‡é•¿
            source_id = f"X_{source_id[:27]}"

            await cur.execute(
                """
                INSERT INTO sora_content (source_id, file_type, owner_user_id, stage)
                VALUES (%s, 'album', %s, 'pending')
                """,
                (source_id, user_id)
            )

            # å–å¾—æ–° content_id
            await cur.execute("SELECT LAST_INSERT_ID() AS cid")
            row = await cur.fetchone()
            if not row:
                raise Exception("Failed to create sora_content")
            content_id = int(row["cid"])

            # 3) å»ºç«‹ productï¼ˆæ–‡ä»¶ç±»å‹ albumï¼‰
            # await cls.create_product(content_id, name='', desc='', price=34, file_type='album', user_id=user_id)
            await cur.execute(
                """
                INSERT INTO product
                    (content_id, file_type, owner_user_id, review_status, price,stage)
                VALUES
                    (%s, 'album', %s, 0, 34,'pending')
                """,
                (content_id, user_id)
            )

            await conn.commit()
            return content_id

        except Exception:
            try:
                await conn.rollback()
            except:
                pass
            raise
        finally:
            await cls.release(conn, cur)


    #è¦å’Œ lz_db.py ä½œæ•´åˆ
    @classmethod
    async def search_sora_content_by_id(cls, content_id: int,bot_username: str):

        # cache_key = f"content_id:{content_id}"
        # cached = cls.cache.get(cache_key)
        # if cached:
        #     print(f"ğŸ”¹ MemoryCache hit for {cache_key}")
        #     return cached
        
        conn, cursor = await cls.get_conn_cursor()
        try:
            await cursor.execute('''
                SELECT s.id, s.source_id, s.file_type, s.content, s.file_size, s.duration, s.tag,
                    s.thumb_file_unique_id, s.file_password,
                    m.file_id AS m_file_id, m.thumb_file_id AS m_thumb_file_id,
                    p.price as fee, p.file_type as product_type, p.owner_user_id, p.purchase_condition, p.review_status, p.anonymous_mode, p.id as product_id,
                    g.guild_id, g.guild_keyword, g.guild_resource_chat_id, g.guild_resource_thread_id, g.guild_chat_id, g.guild_thread_id
                FROM sora_content s
                LEFT JOIN sora_media m ON s.id = m.content_id AND m.source_bot_name = %s
                LEFT JOIN product p ON s.id = p.content_id
                LEFT JOIN guild g ON p.guild_id = g.guild_id
                WHERE s.id = %s
                '''
            , (bot_username, content_id))
            row = await cursor.fetchone()

            # æ²¡æŸ¥åˆ°å°±è¿”å› Noneï¼Œäº¤ç”±ä¸Šå±‚å¤„ç†é»˜è®¤å€¼
            if not row:
                return None

            # 2) å…ˆæ‹¿ m è¡¨çš„ç¼“å­˜
            file_id = row.get("m_file_id")
            thumb_file_id = row.get("m_thumb_file_id")

        

            if(file_id == None and thumb_file_id == None):
                await cursor.execute(
                    """
                    INSERT INTO sora_media (content_id, source_bot_name, thumb_file_id, file_id)
                    VALUES (%s, %s, %s, %s)
                    ON DUPLICATE KEY UPDATE
                        thumb_file_id = VALUES(thumb_file_id),
                        file_id      = VALUES(file_id)
                    """,
                    (content_id, bot_username, '', '')
                )


            # 3) éœ€è¦è¡¥çš„è¯ï¼Œå†å» file_extension æŸ¥
            need_lookup_keys = []
            if not file_id and row.get("source_id"):
                need_lookup_keys.append(row["source_id"])
            if not thumb_file_id and row.get("thumb_file_unique_id"):
                # é¿å…ä¸ source_id é‡å¤
                if row["thumb_file_unique_id"] not in need_lookup_keys:
                    need_lookup_keys.append(row["thumb_file_unique_id"])

            if need_lookup_keys:
                # åŠ¨æ€ IN å ä½
                placeholders = ",".join(["%s"] * len(need_lookup_keys))
                params = [*need_lookup_keys, bot_username]

                await cursor.execute(
                    f'''
                    SELECT file_unique_id, file_id
                    FROM file_extension
                    WHERE file_unique_id IN ({placeholders})
                      AND bot = %s
                    ''',
                    params
                )
                extension_rows = await cursor.fetchall()
                ext_map = {r["file_unique_id"]: r["file_id"] for r in extension_rows}

                updated = False
                if not file_id and row.get("source_id") in ext_map:
                    file_id = ext_map[row["source_id"]]
                    row["m_file_id"] = file_id
                    updated = True

                if not thumb_file_id and row.get("thumb_file_unique_id") in ext_map:
                    thumb_file_id = ext_map[row["thumb_file_unique_id"]]
                    row["m_thumb_file_id"] = thumb_file_id
                    updated = True

                # 4) å¦‚æœè¡¥åˆ°äº†ï¼Œå°±å›å†™ sora_mediaï¼ˆUPSERTï¼‰
                if updated:
                    await cursor.execute(
                        """
                        INSERT INTO sora_media (content_id, source_bot_name, thumb_file_id, file_id)
                        VALUES (%s, %s, %s, %s)
                        ON DUPLICATE KEY UPDATE
                          thumb_file_id = VALUES(thumb_file_id),
                          file_id      = VALUES(file_id)
                        """,
                        (content_id, bot_username, thumb_file_id, file_id)
                    )
                    # å¦‚æœä½ è¿™è¾¹ç”¨æ‰‹åŠ¨äº‹åŠ¡ï¼Œå¯è€ƒè™‘åœ¨å¤–å±‚ç»Ÿä¸€æäº¤

            # cls.cache.set(cache_key, row, ttl=300)

            return row
        except Exception as e:
            print(f"âš ï¸ æ•°æ®åº“æ‰§è¡Œå‡ºé”™: {e}")
            row = None
        finally:
            await cls.release(conn, cursor)

        if not row:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…è®°å½• file_id")
            return None

    @classmethod
    async def get_preview_thumb_file_id(cls, bot_username: str, content_id: int):
        print(f"â–¶ï¸ æ­£åœ¨è·å–ç¼©ç•¥å›¾(get_preview_thumb_file_id) file_id for content_id: {content_id} by bot: {bot_username}", flush=True)
        conn, cur = await cls.get_conn_cursor()
        try:
            # 1. æŸ¥ sora_media
            await cur.execute(
                "SELECT thumb_file_id FROM sora_media WHERE source_bot_name = %s AND content_id = %s LIMIT 1",
                (bot_username, content_id)
            )
            row = await cur.fetchone()
            if row and row["thumb_file_id"]:
                return row["thumb_file_id"], None

            # 2. æŸ¥ sora_content
            print(f"...âŒ sora_media ç›®å‰ä¸å­˜åœ¨  for content_id: {content_id}")
            await cur.execute(
                "SELECT thumb_file_unique_id FROM sora_content WHERE id = %s",
                (content_id,)
            )
            row = await cur.fetchone()
            if not row or not row["thumb_file_unique_id"]:
                return None, None
            thumb_uid = row["thumb_file_unique_id"]

            # 3. æŸ¥ file_extension
           
            await cur.execute(
                "SELECT file_id, bot FROM file_extension WHERE file_unique_id = %s AND bot = %s",
                (thumb_uid,bot_username)
            )
            row = await cur.fetchone()
            if row:
                thumb_file_id = row["file_id"]
                await cur.execute(
                    """
                    INSERT INTO sora_media (content_id, source_bot_name, thumb_file_id)
                    VALUES (%s, %s, %s)
                    ON DUPLICATE KEY UPDATE thumb_file_id = VALUES(thumb_file_id)
                    """,
                    (content_id, bot_username, thumb_file_id)
                )
                print(f"...âœ… æœ‰ç¼©ç•¥å›¾ï¼Œæ­£åœ¨æ›´æ–°: {thumb_file_id} for content_id: {content_id}")
                return thumb_file_id, thumb_uid
            else:
                print(f"...âŒ å…¶ä»–æœºå™¨äººæœ‰ç¼©ç•¥å›¾ï¼Œé€šçŸ¥æ›´æ–° file_id for thumb_uid: {thumb_uid}")
                return None,thumb_uid
                

        finally:
            await cls.release(conn, cur)


    @classmethod
    async def get_default_preview_thumb_file_id(cls, bot_username: str, file_unqiue_id: str):
        print(f"â–¶ï¸ æ­£åœ¨è·å–ç¼©ç•¥å›¾(get_default_preview_thumb_file_id) file_id for file_unqiue_id: {file_unqiue_id} by bot: {bot_username}", flush=True)
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                "SELECT file_id, bot FROM file_extension WHERE file_unique_id = %s AND bot = %s",
                (file_unqiue_id,bot_username)
            )
            row = await cur.fetchone()
            
            if row and row["file_id"]:
                return row["file_id"]
            
                

        finally:
            await cls.release(conn, cur)




    @classmethod
    async def insert_album_item(cls, content_id: int, member_content_id: int, file_unique_id: str | None = None, file_type: str | None = None, position: int = 0):
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                """
                INSERT IGNORE INTO album_items (
                    content_id, member_content_id, file_unique_id, file_type, position, created_at
                )
                VALUES (%s, %s, %s, %s, %s, NOW())
                """,
                (content_id, member_content_id, file_unique_id, file_type, position)
            )
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def get_album_list(cls, content_id: int, bot_name: str) -> list[dict]:
        """
        æŸ¥è¯¢æŸä¸ª album ä¸‹çš„æ‰€æœ‰æˆå‘˜æ–‡ä»¶ï¼ˆMySQL ç‰ˆï¼Œé€‚é… aiomysqlï¼‰
        - é€»è¾‘åŒæ­¥ PostgreSQL ç‰ˆæœ¬ï¼š
        1) å– album_items -> sora_content -> sora_mediaï¼ˆæŒ‰ bot è¿‡æ»¤ï¼‰ï¼›
        2) è‹¥ m.file_id ä¸ºç©ºä¸” file_extension èƒ½åŒ¹é…å‡º ext_file_idï¼Œåˆ™å›å¡«åˆ°è¿”å›å€¼ï¼›
        3) æ‰¹é‡ UPSERT å›å†™ sora_media(content_id, source_bot_name) çš„ file_idã€‚
        - è¿”å›ï¼šlist[dict]
        """
        # è¯´æ˜ï¼š
        # - éœ€è¦å”¯ä¸€é”®/è”åˆç´¢å¼•ï¼šsora_media(content_id, source_bot_name) UNIQUE
        # - JOIN file_extension ä½¿ç”¨ (file_unique_id, bot)
        sql = """
            SELECT
                c.member_content_id,           -- å›å†™ sora_media.content_id ä½¿ç”¨
                s.source_id,
                c.file_type,
                s.content,
                s.file_size,
                s.duration,
                m.source_bot_name,
                m.thumb_file_id,
                m.file_id,
                fe.file_id AS ext_file_id
            FROM album_items AS c
            LEFT JOIN sora_content AS s
                ON c.member_content_id = s.id
            LEFT JOIN sora_media   AS m
                ON c.member_content_id = m.content_id
                AND m.source_bot_name   = %s
            LEFT JOIN file_extension AS fe
                ON fe.file_unique_id = s.source_id
                AND fe.bot            = %s
            WHERE c.content_id = %s
            ORDER BY c.file_type
        """
        params = (bot_name, bot_name, content_id)

        upsert_sql = """
            INSERT INTO sora_media (content_id, source_bot_name, file_id)
            VALUES (%s, %s, %s)
            ON DUPLICATE KEY UPDATE file_id = VALUES(file_id)
        """

        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(sql, params)
            rows = await cur.fetchall() or []

            dict_rows: list[dict] = []
            to_upsert: list[tuple[int, str, str]] = []  # (content_id, bot_name, file_id)

            for d in rows:
                # d å·²æ˜¯ dictï¼ˆDictCursorï¼‰
                file_id = d.get("file_id")
                ext_id  = d.get("ext_file_id")
                # å¦‚æœ m.file_id ä¸ºç©ºä¸”æ‰©å±•è¡¨èƒ½å‘½ä¸­ï¼Œåˆ™ç”¨ ext_file_id å›å¡«è¿”å›å€¼å¹¶å‡†å¤‡å›å†™
                if not file_id and ext_id:
                    d["file_id"] = ext_id
                    cid = d.get("member_content_id")
                    if cid:
                        to_upsert.append((int(cid), bot_name, str(ext_id)))
                dict_rows.append(d)

            # æ‰¹é‡ UPSERT å›å†™ sora_media
            if to_upsert:
                await cur.executemany(upsert_sql, to_upsert)
                await conn.commit()

            return dict_rows
        except Exception:
            try:
                await conn.rollback()
            except Exception:
                pass
            raise
        finally:
            await cls.release(conn, cur)


    @classmethod
    async def get_album_list_old(cls, content_id: int, bot_name: str):
        # TODO  å†™æ³•å’Œ lz_db.py ç›®å‰ä¸åŒ, éœ€ä¿æŒä¸€è‡´ï¼Œæ–¹ä¾¿æ•´åˆ
        sql = """
            SELECT s.source_id, c.file_type, s.content, s.file_size, s.duration,
                   m.source_bot_name, m.thumb_file_id, m.file_id
            FROM album_items c
            LEFT JOIN sora_content s ON c.member_content_id = s.id
            LEFT JOIN sora_media m ON c.member_content_id = m.content_id AND m.source_bot_name = %s
            WHERE c.content_id = %s
            ORDER BY c.file_type
        """
        params = (bot_name, content_id )
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(sql, params)
            return await cur.fetchall()
        finally:
            await cls.release(conn, cur)



    @classmethod
    async def find_rebate_receiver_id(cls, source_id: str, tag: str):
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                """
                SELECT receiver_id,receiver_fee,transaction_timestamp
                FROM transaction
                WHERE transaction_type = 'rebate'
                  AND transaction_description = %s
                  AND memo = %s
                """,
                (source_id, tag)
            )
            row = await cur.fetchone()
            return {
                'receiver_id': row["receiver_id"],
                'receiver_fee': row["receiver_fee"],
                'transaction_timestamp': row["transaction_timestamp"]
            } if row else None
            
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def delete_file_tag(cls, source_id: str, tag: str) -> int:
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                """
                DELETE FROM file_tag
                WHERE tag = %s AND file_unique_id = %s
                """,
                (tag, source_id)
            )
            return cur.rowcount
        finally:
            await cls.release(conn, cur)


    @classmethod
    async def get_all_tag_types(cls):


        now = time.time()
        if cls._all_tags_types_cache and now - cls._all_tags_types_cache_ts < cls._cache_ttl:
            return cls._all_tags_types_cache  # âœ… å‘½ä¸­ç¼“å­˜


        async with cls._pool.acquire() as conn:
            async with conn.cursor(aiomysql.DictCursor) as cur:
                await cur.execute("SELECT type_code, type_cn FROM tag_type WHERE type_code NOT IN ('xiaoliu','system','serial','gallery','gallery_set') " \
                "ORDER BY FIELD(type_code, 'age', 'face', 'act', 'nudity','par', 'fetish','att', 'feedback', 'pro','eth', 'position', 'hardcore', 'position', 'hardcore')")
                # return await cur.fetchall()
                rows = await cur.fetchall()

        
        # âœ… æ›´æ–°ç¼“å­˜
        cls._all_tags_types_cache = rows
        cls._all_tags_types_cache_ts = now
        
        return rows




    @classmethod
    async def get_tags_by_type(cls, type_code: str):
        async with cls._pool.acquire() as conn:
            async with conn.cursor(aiomysql.DictCursor) as cur:
                await cur.execute("""
                    SELECT tag, tag_cn 
                    FROM tag 
                    WHERE tag_type = %s 
                    ORDER BY tag_cn ASC
                """, (type_code,))
                return await cur.fetchall()



    @classmethod
    async def get_content_id_by_file_unique_id(cls, file_unique_id: str) -> str:
        cache_key = f"file_unique_id:{file_unique_id}"
        cached = cls.cache.get(cache_key)
        if cached:
            print(f"ğŸ”¹ MemoryCache hit for {cache_key}")
            return cached
        
        
        async with cls._pool.acquire() as conn:
            async with conn.cursor() as cur:
                await cur.execute("""
                    SELECT id,source_id as file_unique_id 
                    FROM sora_content 
                    WHERE source_id = %s
                """, (file_unique_id,))
                row = await cur.fetchone()
                content_id = row[0] if row else ""
                cls.cache.set(cache_key, content_id, ttl=30000)
                return content_id



    @classmethod
    async def get_content_ids_by_fuids(cls, fuids: list[str]) -> dict[str, int]:
        """
        æ‰¹é‡æŸ¥è¯¢ source_id -> content_id çš„æ˜ å°„ã€‚
        """
        if not fuids:
            return {}
        await cls.init_pool()
        # å»é‡é¿å… IN è¿‡é•¿
        fuids = list({f for f in fuids if f})
        placeholders = ",".join(["%s"] * len(fuids))
        sql = f"""
            SELECT id, source_id 
            FROM sora_content 
            WHERE source_id IN ({placeholders})
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(sql, fuids)
            rows = await cur.fetchall() or []
            return {r["source_id"]: int(r["id"]) for r in rows}
        finally:
            await cls.release(conn, cur)


    @classmethod
    async def insert_sora_content_media_bulk(cls, rows: list[dict], *, batch_size: int = 200) -> list[dict]:
        """
        æ‰¹é‡ upsert ç¼ºå¤±çš„æˆå‘˜åˆ° sora_content + åˆå§‹åŒ– sora_mediaï¼ˆfile_id å¯ä¸ºç©ºï¼‰
        rows æ¯é¡¹ï¼š{
            "file_unique_id": "...",   # source_id
            "file_type": "v|d|p|n",    # çŸ­ç /å…¨åå‡å¯ï¼Œå†…éƒ¨ç»Ÿä¸€
            "file_size": int,
            "duration": int,
            "owner_user_id": str|int,
            "file_id": str|None,
            "bot_username": str
        }
        è¿”å›ï¼šåŒ…å«æ¯æ¡ {file_unique_id, content_id} çš„åˆ—è¡¨
        """
        if not rows:
            return []

        # ç»Ÿä¸€ç±»å‹
        def norm_ft(ft: str) -> str:
            m = {"v":"video","video":"video","d":"document","document":"document",
                "p":"photo","photo":"photo","n":"animation","animation":"animation","a":"album","album":"album"}
            return m.get((ft or "").lower(), "document")

        await cls.init_pool()
        # å…ˆå¯¹ sora_content åšæ‰¹é‡ upsert
        from math import ceil
        # åªä¿ç•™å¿…è¦åˆ—ï¼ˆsora_content ä¸åƒ file_id/botï¼‰
        sc_rows = []
        for r in rows:
            sc_rows.append({
                "source_id": r.get("file_unique_id"),
                "file_type": norm_ft(r.get("file_type")),
                "file_size": r.get("file_size", 0),
                "duration": r.get("duration", 0),
                "owner_user_id": r.get("owner_user_id", 0),
            })
        # è¿‡æ»¤ç©º source_id
        sc_rows = [r for r in sc_rows if r["source_id"]]

        # ç»„è£…å¤šå€¼ INSERT ... ON DUPLICATE
        keys = ["source_id","file_type","file_size","duration","owner_user_id"]
        placeholders = ",".join(["%s"] * len(keys))
        updates = ",".join(f"`{k}`=VALUES(`{k}`)" for k in keys if k != "owner_user_id") + ", `stage`='pending'"
        base_sql = f"""
            INSERT INTO sora_content ({",".join(keys)}, stage)
            VALUES {{values}}
            ON DUPLICATE KEY UPDATE {updates}
        """

        conn, cur = await cls.get_conn_cursor()
        try:
            # åˆ†æ‰¹ upsert sora_content
            total_batches = ceil(len(sc_rows) / batch_size) or 1
            for i in range(total_batches):
                chunk = sc_rows[i*batch_size:(i+1)*batch_size]
                if not chunk:
                    continue
                vals, blocks = [], []
                for r in chunk:
                    vals.extend([r[k] for k in keys] + ["pending"])
                    blocks.append(f"({placeholders}, %s)")  # å¤šä¸€ä¸ª stage
                sql = base_sql.format(values=",".join(blocks))
                await cur.execute(sql, vals)
            # ä¸ºäº†æ‹¿ content_idï¼Œå†æŸ¥å›ï¼ˆä¸€æ¬¡æ€§ INï¼‰
            fuids = [r["source_id"] for r in sc_rows]
            mapping = await cls.get_content_ids_by_fuids(fuids)

            # åˆå§‹åŒ– sora_mediaï¼ˆæŠŠ file_id ä¸ bot_username æ‰¹é‡ upsertï¼‰
            sm_triplets = []
            for r in rows:
                fuid = r.get("file_unique_id")
                cid = mapping.get(fuid)
                if not cid:
                    continue
                sm_triplets.append((
                    int(cid),
                    r.get("bot_username"),
                    r.get("file_id") or "",
                ))

            if sm_triplets:
                await cur.executemany(
                    """
                    INSERT INTO sora_media (content_id, source_bot_name, file_id)
                    VALUES (%s, %s, %s)
                    ON DUPLICATE KEY UPDATE
                    file_id = VALUES(file_id)
                    """,
                    sm_triplets
                )

            await conn.commit()
            return [{"file_unique_id": f, "content_id": mapping.get(f)} for f in fuids if mapping.get(f)]
        except Exception:
            try:
                await conn.rollback()
            except:
                pass
            raise
        finally:
            await cls.release(conn, cur)


    @classmethod
    async def insert_album_items_bulk(cls, content_id: int, members: list[tuple[int, str, int]]):
        """
        æ‰¹é‡æ’å…¥ album_itemsï¼š
        members: [(member_content_id, file_type_short, position), ...]
        file_type_short: 'v'/'d'/'p'/'n'
        """
        if not members:
            return 0
        await cls.init_pool()
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.executemany(
                """
                INSERT IGNORE INTO album_items (content_id, member_content_id, file_type, position)
                VALUES (%s, %s, %s, %s)
                """,
                [(content_id, mid, ft, pos) for (mid, ft, pos) in members]
            )
            affected = cur.rowcount
            await conn.commit()
            return affected
        except Exception:
            try:
                await conn.rollback()
            except:
                pass
            raise
        finally:
            await cls.release(conn, cur)


    @classmethod
    async def finalize_content_fields(cls, candidates,content_id, user_id, bot_username):
        # 5) æ‰¹é‡è¡¥é½æ‰€æœ‰æˆå‘˜ content_id
        fuids = [c.get("file_unique_id") for c in candidates if c.get("file_unique_id")]
        exist_map = await cls.get_content_ids_by_fuids(fuids)  # {fuid: content_id}

        missing_rows = []
        for c in candidates:
            fuid = c.get("file_unique_id")
            if not fuid:
                continue
            if fuid not in exist_map:
                missing_rows.append({
                    "file_unique_id": fuid,
                    "file_type": c.get("file_type"),
                    "file_size": c.get("file_size", 0),
                    "duration": c.get("duration", 0),
                    "owner_user_id": user_id,
                    "file_id": c.get("file_id"),
                    "bot_username": bot_username,
                })

        # æ‰¹é‡æ’å…¥ç¼ºå¤±æˆå‘˜ï¼ˆå«åˆå§‹åŒ– sora_mediaï¼‰
        if missing_rows:
            inserted = await cls.insert_sora_content_media_bulk(missing_rows)
            for r in inserted:
                exist_map[r["file_unique_id"]] = int(r["content_id"])

        # 6) æ‰¹é‡å†™å…¥ album_itemsï¼ˆæŒ‰ candidates é¡ºåºè®¾ç½® positionï¼‰
        members = []
        pos = 1
        def to_short(ft: str) -> str:
            FT_SHORT = {"video": "v", "document": "d", "photo": "p", "animation": "n", "album": "a"}
            if not ft: return "d"
            ft = ft.lower()
            if ft in ("v","d","p","n","a"): return ft
            return FT_SHORT.get(ft, "d")

        for c in candidates:
            fuid = c.get("file_unique_id")
            member_cid = exist_map.get(fuid)
            if not member_cid:
                continue
            members.append( (int(member_cid), to_short(c.get("file_type")), pos) )
            pos += 1

        if members:
            await cls.insert_album_items_bulk(content_id, members)

    @classmethod
    async def get_tags_for_file(cls, file_unique_id: str) -> list[str]:
        async with cls._pool.acquire() as conn:
            async with conn.cursor() as cur:
                await cur.execute("""
                    SELECT tag FROM file_tag 
                    WHERE file_unique_id = %s
                """, (file_unique_id,))
                rows = await cur.fetchall()
                return [r[0] for r in rows]

    @classmethod
    async def is_tag_exist(cls, file_unique_id: str, tag: str) -> bool:
        async with cls._pool.acquire() as conn:
            async with conn.cursor() as cur:
                await cur.execute("""
                    SELECT 1 FROM file_tag 
                    WHERE file_unique_id = %s AND tag = %s
                    LIMIT 1
                """, (file_unique_id, tag))
                return bool(await cur.fetchone())

    @classmethod
    async def add_tag(cls, file_unique_id: str, tag: str) -> bool:
        async with cls._pool.acquire() as conn:
            async with conn.cursor() as cur:
                await cur.execute("""
                    INSERT INTO file_tag (file_unique_id, tag, count) 
                    VALUES (%s, %s, 0)
                """, (file_unique_id, tag))
                await conn.commit()
                return True

    @classmethod
    async def remove_tag(cls, file_unique_id: str, tag: str) -> bool:
        async with cls._pool.acquire() as conn:
            async with conn.cursor() as cur:
                await cur.execute("""
                    DELETE FROM file_tag 
                    WHERE file_unique_id = %s AND tag = %s
                """, (file_unique_id, tag))
                await conn.commit()
                return True

    @classmethod
    async def get_tag_info(cls, tag: str) -> dict:
        async with cls._pool.acquire() as conn:
            async with conn.cursor(aiomysql.DictCursor) as cur:
                await cur.execute("""
                    SELECT tag, tag_type 
                    FROM tag 
                    WHERE tag = %s
                """, (tag,))
                return await cur.fetchone()

    @classmethod
    async def get_all_tags_grouped(cls) -> dict:
        """
        è¿”å›ç»“æ„:
        {
        "style": [ {tag: "...", tag_cn: "..."}, ... ],
        "mood": [ ... ],
        ...
        }
        """
        now = time.time()
        if cls._all_tags_grouped_cache and now - cls._all_tags_grouped_cache_ts < cls._cache_ttl:
            return cls._all_tags_grouped_cache  # âœ… å‘½ä¸­ç¼“å­˜


        async with cls._pool.acquire() as conn:
            async with conn.cursor(aiomysql.DictCursor) as cur:
                await cur.execute("SELECT tag, tag_cn, tag_type FROM tag ")
                rows = await cur.fetchall()
        
        grouped = {}
        for row in rows:
            grouped.setdefault(row["tag_type"], []).append(row)
        # âœ… æ›´æ–°ç¼“å­˜
        cls._all_tags_grouped_cache = grouped
        cls._all_tags_grouped_cache_ts = now
        
        return grouped

    @classmethod
    async def sync_file_tags(cls, file_unique_id: str, selected_tags: set[str], *, actor_user_id: int | None = None) -> dict:
        """
        å°† FSM é‡Œæœ€ç»ˆé€‰ä¸­çš„æ ‡ç­¾ä¸€æ¬¡æ€§è½åº“ï¼š
        - æ–°å¢ï¼šINSERT ... ON DUPLICATE KEY UPDATEï¼ˆcount é»˜è®¤ä¸º 1ï¼Œå¯æŒ‰éœ€æ”¹æˆè®¡æ•°é€»è¾‘ï¼‰
        - ç§»é™¤ï¼šDELETE ... WHERE tag IN (...)
        è¿”å› {added: n, removed: m, unchanged: k}
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            # å–å½“å‰åº“é‡Œçš„æ ‡ç­¾
            await cur.execute(
                "SELECT tag FROM file_tag WHERE file_unique_id=%s",
                (file_unique_id,)
            )
            existing = {row["tag"] for row in await cur.fetchall()}

            to_add = list(selected_tags - existing)
            to_del = list(existing - selected_tags)
            unchanged = len(existing & selected_tags)

            # æ‰¹é‡æ–°å¢
            if to_add:
                rows = [(file_unique_id, t, 1) for t in to_add]
                await cur.executemany(
                    """
                    INSERT INTO file_tag (file_unique_id, tag, `count`)
                    VALUES (%s, %s, %s)
                    ON DUPLICATE KEY UPDATE `count`=VALUES(`count`)
                    """,
                    rows
                )

            # æ‰¹é‡åˆ é™¤
            if to_del:
                # åŠ¨æ€ IN åˆ—è¡¨
                ph = ",".join(["%s"] * len(to_del))
                await cur.execute(
                    f"DELETE FROM file_tag WHERE file_unique_id=%s AND tag IN ({ph})",
                    (file_unique_id, *to_del)
                )

            await conn.commit()
            return {"added": len(to_add), "removed": len(to_del), "unchanged": unchanged}
        except Exception:
            await conn.rollback()
            raise
        finally:
            await cls.release(conn, cur)


    @classmethod
    async def get_tag_cn_batch(cls, tags: list[str]) -> dict[str, str]:
        """
        æ‰¹é‡å– tag -> tag_cn çš„æ˜ å°„ï¼›è‹¥æ²¡æœ‰ tag_cnï¼Œåˆ™å›é€€ tag æœ¬èº«ã€‚
        è¿”å›: {tag: tag_cn_or_tag}
        """
        if not tags:
            return {}
        conn, cur = await cls.get_conn_cursor()
        try:
            ph = ",".join(["%s"] * len(tags))
            await cur.execute(
                f"SELECT tag, COALESCE(tag_cn, tag) AS tag_cn FROM tag WHERE tag IN ({ph})",
                tuple(tags)
            )
            rows = await cur.fetchall()
            mapping = {r["tag"]: r["tag_cn"] for r in rows}
            # æ²¡æŸ¥åˆ°çš„ï¼Œç”¨è‡ªèº«å›å¡«
            for t in tags:
                mapping.setdefault(t, t)
            return mapping
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def update_sora_content_tag_and_stage(cls, content_id: int, tag_str: str):
        """
        æ›´æ–° sora_content.tag ä¸ stage='pending'
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            print(f"â–¶ï¸ æ­£åœ¨æ›´æ–° sora_content.tag={tag_str} for content_id: {content_id}", flush=True)
            await cur.execute(
                "UPDATE sora_content SET tag=%s, stage='pending' WHERE id=%s",
                (tag_str, content_id)
            )
            await conn.commit()
        except Exception:
            await conn.rollback()
            raise
        finally:
            await cls.release(conn, cur)



    @classmethod
    async def update_product_content(cls, content_id: int, content: str, user_id: int = 0, overwrite: int = 0):
        # âœ… ç”¨æ›´å‡†ç¡®çš„åç§°
        timer = SegTimer("update_product_content", content_id=content_id, overwrite=int(overwrite))
        
        # å…è®¸çš„è¡¨åç™½åå•ï¼ˆæ ‡è¯†ç¬¦ä¸èƒ½ç”¨å ä½ç¬¦ï¼Œåªèƒ½å…ˆéªŒè¯å†æ‹¼æ¥ï¼‰
        FT_MAP = {
            "d": "document", "document": "document",
            "v": "video",    "video": "video",
            "p": "photo",    "photo": "photo",
        }

        try:
            cls.init_pool()
            async with cls._pool.acquire() as conn:
                async with conn.cursor() as cur:
                    timer.lap("acquire_conn_and_cursor")

                    # --- è¦†å†™æ¨¡å¼ï¼šéœ€è¦å…ˆä» sora_content åæŸ¥æºè¡¨ä¸åŸå§‹ caption ---
                    if int(overwrite) == 1:
                        # 1) å– sora_content åŸºæœ¬ä¿¡æ¯
                        await cur.execute(
                            "SELECT source_id, file_type FROM sora_content WHERE id = %s LIMIT 1",
                            (content_id,)
                        )
                        row_sora_content = await cur.fetchone()
                        timer.lap("fetch_sora_content")

                        if row_sora_content:
                            src_id = row_sora_content[0]
                            file_type = row_sora_content[1]
                            ft_norm = FT_MAP.get(file_type)

                            if not ft_norm:
                                print(f"[update_product_content] Unsupported file_type={file_type} for id={content_id}", flush=True)
                            else:
                                # 2) å–å¯¹åº”åª’ä½“è¡¨ captionï¼ˆè¡¨åç”¨ç™½åå• + åå¼•å·ï¼‰
                                await cur.execute(
                                    f"SELECT caption FROM `{ft_norm}` WHERE file_unique_id = %s LIMIT 1",
                                    (src_id,)
                                )
                                origin_content_row = await cur.fetchone()
                                origin_content = origin_content_row[0] if origin_content_row else ""
                                timer.lap("fetch_origin_caption")

                                # 3) å¤‡ä»½ä¸€ä»½åˆ° material_captionï¼ˆåªæ’å…¥ä¸€æ¬¡ï¼‰
                                await cur.execute(
                                    "INSERT INTO `material_caption` (`file_unique_id`, `caption`, `user_id`) VALUES (%s, %s, %s)",
                                    (src_id, origin_content, user_id)
                                )
                                timer.lap("insert_material_caption")

                                # 4) æ›´æ–°åª’ä½“è¡¨ caption ä¸ kc_id / kc_status
                                if ft_norm in ("video"):
                                    await cur.execute(
                                        f"UPDATE `{ft_norm}` "
                                        f"SET caption = %s, kc_id = %s, update_time = NOW(), kc_status = 'pending' "
                                        f"WHERE file_unique_id = %s",
                                        (content, content_id, src_id)
                                    )
                                else:
                                    await cur.execute(
                                        f"UPDATE `{ft_norm}` "
                                        f"SET caption = %s, kc_id = %s, kc_status = 'pending' "
                                        f"WHERE file_unique_id = %s",
                                        (content, content_id, src_id)
                                    )
                                timer.lap("update_media_table")

                    # --- ä¸è®ºæ˜¯å¦ overwriteï¼Œéƒ½éœ€è¦åŒæ­¥ product / sora_content ---
                    await cur.execute(
                        "UPDATE product SET content = %s, stage='pending' WHERE content_id = %s",
                        (content, content_id)
                    )
                    timer.lap("update_product")

                    await cur.execute(
                        "UPDATE sora_content SET content = %s, stage='pending' WHERE id = %s",
                        (content, content_id)
                    )
                    timer.lap("update_sora_content")

                await conn.commit()
                timer.lap("commit")
        except Exception as e:
            # å¤±è´¥æ—¶å°è¯•å›æ»š
            try:
                await conn.rollback()
            except Exception:
                pass
            print(f"[update_product_content] ERROR: {e}", flush=True)
            raise
        finally:
            timer.end()


    @classmethod
    async def update_product_file_type(cls, content_id: int, file_type: str):
        async with cls._pool.acquire() as conn:
            async with conn.cursor() as cur:
                await cur.execute(
                    "UPDATE product SET file_type = %s, stage='pending' WHERE content_id = %s",
                    (file_type, content_id)
                )
                await conn.commit()

    #search_sora_content_by_id
    @classmethod
    async def get_sora_content_by_id(cls, content_id: int):
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute("SELECT * FROM sora_content WHERE id = %s", (content_id,))
            return await cur.fetchone()
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def get_bid_thumbnail_by_source_id(cls, source_id: str):
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute("SELECT b.thumb_file_unique_id, f.file_id as thumb_file_id, b.bot_name FROM bid_thumbnail b LEFT JOIN file_extension f ON f.file_unique_id = b.thumb_file_unique_id WHERE b.file_unique_id = %s and b.confirm_status >= 10;", (source_id,))
            # await cur.execute("SELECT thumb_file_unique_id FROM bid_thumbnail LEFT JOIN file_extension f ON f.file_unique_id = bid_thumbnail.file_unique_id WHERE bid_thumbnail.file_unique_id = %s", (source_id,))
            return await cur.fetchall()
        finally:
            await cls.release(conn, cur)

    



    @classmethod
    async def get_product_review_status(cls, content_id: int) -> int | None:
        """
        è¯»å–å½“å‰ bid_statusï¼ˆå¯é€‰çš„å¹‚ç­‰æ£€æŸ¥ç”¨ï¼‰ã€‚
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                "SELECT review_status FROM product WHERE content_id=%s",
                (content_id,)
            )
            row = await cur.fetchone()
            return row["review_status"] if row else None
        finally:
            await cls.release(conn, cur)


    @classmethod
    async def get_product_info_by_fuid(cls, file_unique_id: str):
        """
        è¯»å–å½“å‰ bid_statusï¼ˆå¯é€‰çš„å¹‚ç­‰æ£€æŸ¥ç”¨ï¼‰ã€‚
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                "SELECT p.id as product_id,p.owner_user_id,p.review_status,s.thumb_file_unique_id,s.id as content_id FROM sora_content s LEFT JOIN product p ON p.content_id = s.id WHERE s.source_id=%s",
                (file_unique_id,)
            )
            row = await cur.fetchone()
            return row
        finally:
            await cls.release(conn, cur)

        


    @classmethod
    async def set_product_review_status(cls, content_id: int, status: int = 1) -> int:
        """
        å°† product.review_status è®¾ä¸ºæŒ‡å®šå€¼ï¼ˆé»˜è®¤ 1ï¼‰ï¼Œè¿”å›å—å½±å“è¡Œæ•°ã€‚
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                """
                UPDATE product
                   SET review_status=%s,
                       updated_at=NOW(), stage='pending'
                 WHERE content_id=%s
                """,
                (status, content_id)
            )
            affected = cur.rowcount
            await conn.commit()
            return affected
        finally:
            await cls.release(conn, cur)


    @classmethod
    async def sumbit_to_review_product(cls, content_id: int, review_status:int, owner_user_id: int) -> int:
        """
        å°† product.review_status è®¾ä¸ºæŒ‡å®šå€¼ï¼ˆé»˜è®¤ 1ï¼‰ï¼Œè¿”å›å—å½±å“è¡Œæ•°ã€‚
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                """
                UPDATE product
                   SET review_status=%s,
                       updated_at=NOW(), 
                       	owner_user_id = %s,
                       stage='pending'
                 WHERE content_id=%s
                """,
                (review_status, owner_user_id, content_id)
            )
            affected = cur.rowcount
            await conn.commit()
            return affected
        finally:
            await cls.release(conn, cur)



    @classmethod
    async def refine_product_content(cls, content_id: int) -> bool:
        """
        ç²¾ç‚¼äº§å“å†…å®¹ï¼šåˆå¹¶ sora_content.content ä¸å¯¹åº”åª’ä½“è¡¨ captionï¼Œ
        å»é‡/æ¸…æ´—åå›å†™ä¸¤è¾¹ã€‚
        è¿”å› True è¡¨ç¤ºæˆåŠŸï¼ˆå“ªæ€•æ²¡æœ‰å†…å®¹ä¹Ÿç®—æˆåŠŸï¼‰ï¼ŒFalse è¡¨ç¤ºæœªæ‰¾åˆ°è®°å½•ã€‚
        """
        # å…è®¸çš„è¡¨åç™½åå•ï¼ˆæ ‡è¯†ç¬¦ä¸èƒ½ç”¨å ä½ç¬¦ï¼Œåªèƒ½å…ˆéªŒè¯å†æ‹¼æ¥ï¼‰
        FT_MAP = {
            "d": "document", "document": "document",
            "v": "video",    "video": "video",
            "p": "photo",    "photo": "photo"
        }

        conn, cur = await cls.get_conn_cursor()
        try:
            # 1) å– sora_content åŸºæœ¬ä¿¡æ¯
            await cur.execute(
                "SELECT content, source_id, file_type FROM sora_content WHERE id = %s LIMIT 1",
                (content_id,)
            )
            row = await cur.fetchone()
            if not row:
                # æ²¡æœ‰è¿™æ¡ content_id
                return False

            src_id = row["source_id"]
            ft_norm = FT_MAP.get(row["file_type"])
            if not ft_norm:
                # æœªçŸ¥ç±»å‹ï¼Œä¿å®ˆä¸åŠ¨
                print(f"[refine_product_content] Unsupported file_type={row['file_type']!r} for id={content_id}")
                return False

            # 2) å–å¯¹åº”åª’ä½“è¡¨ captionï¼ˆè¡¨åç”¨ç™½åå• + åå¼•å·ï¼‰
            await cur.execute(
                f"SELECT caption FROM `{ft_norm}` WHERE file_unique_id = %s LIMIT 1",
                (src_id,)
            )
            row2 = await cur.fetchone()

            # 3) åˆå¹¶æ–‡æœ¬
            content_parts = []
            if row and row.get("content"):
                content_parts.append(row["content"])
            if row2 and row2.get("caption"):
                content_parts.append(row2["caption"])

            merged = "\n".join(p for p in content_parts if p)  # é¿å… None
            if not merged.strip():
                # æ²¡æœ‰å¯ç²¾ç‚¼çš„å†…å®¹ï¼Œä¹Ÿç®—æµç¨‹æˆåŠŸ
                return True

            # 4) ç²¾ç‚¼ï¼šå»é‡ä¸­æ–‡å¥å­ + æ¸…æ´—
            cleaned = LZString.dedupe_cn_sentences(merged)
            refined = LZString.clean_text(cleaned)

            # 5) å›å†™ sora_content ä¸åª’ä½“è¡¨
            await cur.execute(
                "UPDATE sora_content SET content = %s, stage='pending' WHERE id = %s",
                (refined, content_id)
            )
            if( ft_norm == 'video' or ft_norm == 'document'):
                await cur.execute(
                    f"UPDATE `{ft_norm}` SET caption = %s, kc_id = %s, update_time = NOW(), kc_status = 'pending' WHERE file_unique_id = %s",
                    (refined, content_id, src_id)
                )
            else:
                await cur.execute(
                    f"UPDATE `{ft_norm}` SET caption = %s, kc_id = %s, kc_status = 'pending' WHERE file_unique_id = %s",
                    (refined, content_id, src_id)
                )

            await cur.execute(
                "UPDATE product SET content = %s, stage='pending' WHERE content_id = %s",
                (refined, content_id)
            )


            await conn.commit()
            return True

        except Exception as e:
            await conn.rollback()
            print(f"[refine_product_content] ERROR id={content_id}: {e}")
            raise
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def update_material_caption(cls, content_id: int, content) -> bool:
        """
        æ›´æ–°æ‰€æœ‰çš„äº§å“å†…å®¹ï¼šåˆå¹¶ sora_content.content ä¸å¯¹åº”åª’ä½“è¡¨ captionï¼Œ
        å»é‡/æ¸…æ´—åå›å†™ä¸¤è¾¹ã€‚
        è¿”å› True è¡¨ç¤ºæˆåŠŸï¼ˆå“ªæ€•æ²¡æœ‰å†…å®¹ä¹Ÿç®—æˆåŠŸï¼‰ï¼ŒFalse è¡¨ç¤ºæœªæ‰¾åˆ°è®°å½•ã€‚
        """
        # å…è®¸çš„è¡¨åç™½åå•ï¼ˆæ ‡è¯†ç¬¦ä¸èƒ½ç”¨å ä½ç¬¦ï¼Œåªèƒ½å…ˆéªŒè¯å†æ‹¼æ¥ï¼‰
        FT_MAP = {
            "d": "document", "document": "document",
            "v": "video",    "video": "video",
            "p": "photo",    "photo": "photo",
        }

        conn, cur = await cls.get_conn_cursor()
        try:
            # 1) å– sora_content åŸºæœ¬ä¿¡æ¯
            await cur.execute(
                "SELECT content, source_id, file_type FROM sora_content WHERE id = %s LIMIT 1",
                (content_id,)
            )
            row = await cur.fetchone()
            if not row:
                # æ²¡æœ‰è¿™æ¡ content_id
                return False

            src_id = row["source_id"]
            ft_norm = FT_MAP.get(row["file_type"])
            if not ft_norm:
                # æœªçŸ¥ç±»å‹ï¼Œä¿å®ˆä¸åŠ¨
                print(f"[refine_product_content] Unsupported file_type={row['file_type']!r} for id={content_id}")
                return False

            # 5) å›å†™ sora_content ä¸åª’ä½“è¡¨
            await cur.execute(
                "UPDATE sora_content SET content = %s, stage='pending' WHERE id = %s",
                (content, content_id)
            )
            if( ft_norm == 'video' or ft_norm == 'document'):
                await cur.execute(
                    f"UPDATE `{ft_norm}` SET caption = %s, kc_id = %s, update_time = NOW(), kc_status = 'pending' WHERE file_unique_id = %s",
                    (content, content_id, src_id)
                )
            else:
                await cur.execute(
                    f"UPDATE `{ft_norm}` SET caption = %s, kc_id = %s, kc_status = 'pending' WHERE file_unique_id = %s",
                    (content, content_id, src_id)
                )

            await cur.execute(
                "UPDATE product SET content = %s, stage='pending' WHERE content_id = %s",
                (content, content_id)
            )


            await conn.commit()
            return True

        except Exception as e:
            await conn.rollback()
            print(f"[refine_product_content] ERROR id={content_id}: {e}")
            raise
        finally:
            await cls.release(conn, cur)    


    @classmethod
    async def set_product_guild(cls, content_id: int) -> None:
        conn, cur = await cls.get_conn_cursor()
        guild_id = None
        try:
            # 1) å– sora_content åŸºæœ¬ä¿¡æ¯
            await cur.execute(
                "SELECT source_id FROM sora_content WHERE id = %s LIMIT 1",
                (content_id,)
            )
            file_row = await cur.fetchone()
            if not file_row:
                # æ²¡æœ‰è¿™æ¡ content_id
                print(f"no content id")
                return False
 
            # 2) å–å½’å±çš„ guild_id
            await cur.execute(
                "SELECT a.guild_id FROM `file_tag` t LEFT JOIN tag a ON a.tag = t.tag WHERE t.`file_unique_id` LIKE %s AND a.guild_id IS NOT NULL AND a.guild_id > 0 ORDER BY a.quantity ASC limit 1;",
                # "SELECT g.guild_id FROM `file_tag` t LEFT JOIN guild g ON g.guild_tag = t.tag WHERE t.`file_unique_id` LIKE %s AND g.guild_id IS NOT NULL AND t.quantity > 0 ORDER BY t.quantity ASC limit 1;",
                (file_row["source_id"],)
            )
            file_tag_row = await cur.fetchone()
            if not file_tag_row:
                guild_id = 16
                print(f"no tag")
            else:
                guild_id = file_tag_row["guild_id"]

            print(f"file_tag_row={file_tag_row}")

            await cur.execute(
                """
                UPDATE product
                   SET guild_id=%s,
                       updated_at=NOW(), stage='pending'
                 WHERE content_id=%s
                """,
                (guild_id, content_id)
            )
            affected = cur.rowcount
            await conn.commit()
            return guild_id or None
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def check_guild_role(cls, user_id: int, role: str) -> dict | None:
        """
        æ£€æŸ¥ user_id æ˜¯å¦åœ¨ guild_manager ä¸²ä¸­ (ä»¥ ; åˆ†éš”å¹¶ç»“å°¾)ã€‚
        è¿”å› guild è®°å½• (dict)ï¼Œä¸å­˜åœ¨åˆ™è¿”å› Noneã€‚
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            if role == "owner":
                # ç®¡ç†å‘˜ç›´æ¥è¿”å›ä»»æ„ä¸€æ¡ guild è®°å½•
                await cur.execute(
                    "SELECT * FROM guild WHERE guild_owner LIKE %s LIMIT 1;",
                    (f"%{user_id};%",)
                )

            # æ™®é€šç”¨æˆ·æ£€æŸ¥ guild_manager å­—æ®µ
            elif role == "manager":
                await cur.execute(
                    "SELECT * FROM guild WHERE guild_manager LIKE %s LIMIT 1;",
                    (f"%{user_id};%",)
                )
            
            row = await cur.fetchone()
            return row if row else None
        finally:
            await cls.release(conn, cur)




    # AnanBOTPool å†…éƒ¨
    @classmethod
    async def update_product_anonymous_mode(cls, content_id: int, mode: int) -> int:
        """
        å°† product.anonymous_mode è®¾ç½®ä¸º 1(åŒ¿å) æˆ– 3(å…¬å¼€)
        è¿”å›å—å½±å“è¡Œæ•°
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                """
                UPDATE product
                SET anonymous_mode = %s
                WHERE content_id = %s
                """,
                (mode, content_id)
            )
            await conn.commit()
            return cur.rowcount or 0
        finally:
            await cls.release(conn, cur)

    
    @classmethod
    async def get_trade_url(cls, file_unique_id: str) -> str:
        """
        ç”Ÿæˆäº¤æ˜“/èµ„æºè·³è½¬é“¾æ¥ã€‚
        è¿™é‡Œç»™ä¸€ä¸ªå¯è¿è¡Œçš„å ä½å®ç°ï¼›ä½ å¯æŒ‰ä½ çš„ä¸šåŠ¡æ”¹æˆçœŸå®è½åœ°é¡µã€‚
        """
        # TODO: è‹¥ä½ æœ‰çœŸå®è½åœ°é¡µï¼Œè¯·æ”¹æˆä½ çš„åŸŸåè§„åˆ™
        content_id = await AnanBOTPool.get_content_id_by_file_unique_id(file_unique_id)
        aes = AESCrypto(AES_KEY)
        encoded = aes.aes_encode(content_id)
        shared_url = f"https://t.me/{lz_var.bot_username}?start=f_-1_{encoded}"
        return shared_url

    @classmethod
    async def find_user_reportable_transaction(cls, user_id: int, file_unique_id: str) -> dict | None:
        """
        æŒ‰ PHP é€»è¾‘ï¼šä¼˜å…ˆæŸ¥ä¸è¯¥ file_unique_id ç›¸å…³çš„ 'view' æˆ– 'confirm_buy' è®°å½•ï¼ˆä»»ä¸€å³ç®—æœ‰äº¤æ˜“è®°å½•ï¼‰ã€‚
        è¿”å›ç¬¬ä¸€æ¡å‘½ä¸­è®°å½•ï¼›æ— åˆ™ Noneã€‚
        """
        sql = """
            (SELECT *
             FROM `transaction`
             WHERE sender_id = %s
               AND transaction_type = %s
               AND memo = %s)
            UNION ALL
            (SELECT *
             FROM `transaction`
             WHERE sender_id = %s
               AND transaction_type = %s
               AND transaction_description = %s)
            LIMIT 1
        """
        params = (user_id, "view", file_unique_id, user_id, "confirm_buy", file_unique_id)
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(sql, params)
            row = await cur.fetchone()
            return row if row else None
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def find_existing_report(cls, file_unique_id: str) -> dict | None:
        """
        æŸ¥è¯¢æ˜¯å¦å·²æœ‰é’ˆå¯¹è¯¥ file_unique_id çš„ä¸¾æŠ¥ï¼ˆçŠ¶æ€åœ¨ editing/pending/published/failedï¼‰ã€‚
        æœ‰åˆ™è¿”å›ç¬¬ä¸€æ¡ï¼›æ— åˆ™ Noneã€‚
        """
        sql = """
            SELECT r.*, t.receiver_id as owner_user_id, t.sender_id, t.sender_fee, t.receiver_fee 
              FROM report r
              LEFT JOIN transaction t ON r.transaction_id = t.transaction_id
             WHERE r.process_status IN ('editing', 'pending', 'published', 'failed')
               AND r.file_unique_id = %s
             LIMIT 1
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(sql, (file_unique_id,))
            row = await cur.fetchone()
            return row if row else None
        finally:
           
            await cls.release(conn, cur)

    @classmethod
    async def get_next_report_to_judge(cls) -> dict | None:
        """
        æŸ¥è¯¢æ˜¯å¦å·²æœ‰é’ˆå¯¹è¯¥ file_unique_id çš„ä¸¾æŠ¥ï¼ˆçŠ¶æ€åœ¨ editing/pending/published/failedï¼‰ã€‚
        æœ‰åˆ™è¿”å›ç¬¬ä¸€æ¡ï¼›æ— åˆ™ Noneã€‚
        """
        sql = """
            SELECT * FROM report 
             WHERE process_status IN ('pending')
             LIMIT 1
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(sql)
            row = await cur.fetchone()
            return row if row else None
        finally:
            await cls.release(conn, cur)


    


    # ananbot_utils.py å†…çš„ AnanBOTPool ç±»é‡Œæ–°å¢
    @classmethod
    async def create_report(cls, file_unique_id: str, transaction_id: int, report_type: int, report_reason: str) -> int:
        """
        å‘ report è¡¨æ’å…¥ä¸€æ¡è®°å½•ï¼Œprocess_status='pending'
        è¿”å›è‡ªå¢ report_id
        """
        conn, cursor = await cls.get_conn_cursor()
        try:
            ts = int(datetime.now().timestamp())
            sql = """
                INSERT INTO report
                    (file_unique_id, transaction_id, create_timestamp, report_reason, report_type, process_status1, process_status)
                VALUES
                    (%s, %s, %s, %s, %s, 0, 'pending')
            """
            await cursor.execute(sql, (file_unique_id, transaction_id, ts, report_reason, report_type))
            await conn.commit()
            return cursor.lastrowid  # MyISAM/auto_increment å¯ç”¨
        finally:
            await cls.release(conn, cursor)


    @classmethod
    async def update_bid_owner(cls, file_unique_id: str, new_owner_id: str | int) -> int:
        """
        å°† bid.owner_user_id æ›´æ–°ä¸ºæ–°çš„æ‹¥æœ‰è€…ï¼ˆå¦‚ç³»ç»Ÿè´¦å·ï¼‰
        è¿”å›å—å½±å“è¡Œæ•°
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                "UPDATE bid SET owner_user_id=%s WHERE file_unique_id=%s",
                (str(new_owner_id), file_unique_id)
            )
            affected = cur.rowcount or 0
            await conn.commit()
            return affected
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def update_report_status(cls, report_id: int, status: str) -> int:
        """
        æ›´æ–° report.process_status = 'approved' / 'rejected' / 'pending' ...
        è¿”å›å—å½±å“è¡Œæ•°
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute(
                "UPDATE report SET process_status=%s WHERE report_id=%s",
                (status, report_id)
            )
            affected = cur.rowcount or 0
            await conn.commit()
            return affected
        finally:
            await cls.release(conn, cur)

    # ====== â‘¡ DB è¾…åŠ©å‡½æ•°ï¼šå–å‡ºæ‰€æœ‰ review_status = 2 çš„ content_id ======
    @classmethod
    async def fetch_review_status_content_ids(cls, review_status_id:int, quantity:int = 10) -> list[int]:
        """
        è¿”å›éœ€è¦å‘é€åˆ°å®¡æ ¸ç¾¤ç»„çš„ content_id åˆ—è¡¨ï¼ˆproduct.review_status = 2ï¼‰
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            # è¿™é‡Œå‡è®¾ product è¡¨å­—æ®µä¸º content_idã€review_status
            # è‹¥ä½ è¡¨ç»“æ„ä¸åŒï¼ŒæŠŠåˆ—åæ”¹ä¸ºå®é™…åç§°å³å¯
            await cur.execute(
                "SELECT content_id FROM product WHERE review_status = %s ORDER BY RAND() LIMIT %s",
                (review_status_id, quantity)
            )
            rows = await cur.fetchall()
            # aiomysql.DictCursor æ—¶ï¼šrow æ˜¯ dictï¼›æ™®é€š Cursor æ—¶ï¼šrow æ˜¯ tuple
            ids = []
            for row in rows:
                if isinstance(row, dict):
                    ids.append(int(row.get("content_id")))
                else:
                    ids.append(int(row[0]))
            return ids
        finally:
            await cls.release(conn, cur)


    # =======================
    # Series ç›¸å…³
    # =======================
    @classmethod
    async def get_all_series(cls) -> list[dict]:
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute("SELECT id, name, description, tag FROM series ORDER BY name ASC")
            return await cur.fetchall()
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def get_series_ids_for_file(cls, file_unique_id: str) -> set[int]:
        conn, cur = await cls.get_conn_cursor()
        try:
            await cur.execute("SELECT series_id FROM file_series WHERE file_unique_id=%s", (file_unique_id,))
            rows = await cur.fetchall()
            ids = set()
            for r in rows:
                ids.add(int(r["series_id"] if isinstance(r, dict) else r[0]))
            return ids
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def sync_file_series(cls, file_unique_id: str, selected_ids: set[int]) -> dict:
        """
        ä¸ file_series è¡¨åšä¸€æ¬¡æ€§åŒæ­¥ï¼ˆç±»ä¼¼ sync_file_tags é£æ ¼ï¼‰ï¼š
        - æ–°å¢ï¼šselected_ids - db_ids
        - åˆ é™¤ï¼šdb_ids - selected_ids
        è¿”å› {added, removed, unchanged}
        """
        conn, cur = await cls.get_conn_cursor()
        try:
            # ç°æœ‰
            await cur.execute("SELECT series_id FROM file_series WHERE file_unique_id=%s", (file_unique_id,))
            rows = await cur.fetchall()
            db_ids = {int(r["series_id"] if isinstance(r, dict) else r[0]) for r in rows}

            to_add = list(selected_ids - db_ids)
            to_del = list(db_ids - selected_ids)

            if to_add:
                await cur.executemany(
                    "INSERT INTO file_series (file_unique_id, series_id) VALUES (%s, %s)",
                    [(file_unique_id, sid) for sid in to_add]
                )
            if to_del:
                await cur.executemany(
                    "DELETE FROM file_series WHERE file_unique_id=%s AND series_id=%s",
                    [(file_unique_id, sid) for sid in to_del]
                )
            await conn.commit()

            return {"added": len(to_add), "removed": len(to_del), "unchanged": len(selected_ids & db_ids)}
        finally:
            await cls.release(conn, cur)

    @classmethod
    async def sync_bid_product(cls) -> dict:
        """
        åŒæ­¥ bid â†’ productï¼š
        - å– 10 ç¬” b.content_id IS NULL ä¸”èƒ½åœ¨ sora_content å‘½ä¸­çš„è®°å½•
        - ä»¥ä¸€æ¡ INSERT ... ON DUPLICATE KEY UPDATE èåˆæ’å…¥/æ›´æ–° product
        - product.content = [sora_content.id]ï¼ˆä»¥å­—ç¬¦ä¸²å†™å…¥ï¼Œä¸ä½ ç°æœ‰é£æ ¼ä¸€è‡´ï¼‰
        - product.price = lz_var.default_point
        - product.file_type = [bid.type]
        - product.stage = 'pending'
        - å›å†™ bid.content_id = [sora_content.id]
        """
        print("â–¶ï¸ æ­£åœ¨åŒæ­¥ bid â†’ product ...", flush=True)
        conn, cur = await cls.get_conn_cursor()
        fetched = upserted = bid_updated = 0
        try:
            # 1) æŠ“å–æœ€å¤š 10 ç¬”å€™é€‰
            await cur.execute("""
                SELECT b.file_unique_id,
                    COALESCE(b.type, '') AS file_type,
                    s.id AS content_id
                FROM bid b
                LEFT JOIN sora_content s ON b.file_unique_id = s.source_id
                WHERE b.content_id IS NULL AND CHAR_LENGTH(s.content) > 30
                AND b.file_unique_id IS NOT NULL
                AND s.id IS NOT NULL
                LIMIT 10
            """)
            rows = await cur.fetchall()
            fetched = len(rows)
            if not rows:
                await conn.commit()
                return {"fetched": 0, "product_upserted": 0, "bid_updated": 0}

            # 2) é€ç¬” UPSERT product å¹¶å›å†™ bid
            for r in rows:
                file_unique_id = r["file_unique_id"]
                file_type      = r["file_type"] or ""
                content_id     = int(r["content_id"])

                # å•æ¡ SQL èåˆæ’å…¥/æ›´æ–°
                await cur.execute(
                    """
                    INSERT INTO product
                        ( price, content_id, file_type, review_status, stage, owner_user_id)
                    VALUES
                        (   %s,      %s,    %s,        2,          'pending', 666666)
                    ON DUPLICATE KEY UPDATE
                        price     = VALUES(price),
                        file_type = VALUES(file_type),
                        stage     = 'pending'
                    """,
                    (  lz_var.default_point, content_id, file_type, )
                )
                upserted += 1

                # å›å†™ bid.content_id
                await cur.execute(
                    "UPDATE bid SET content_id = %s WHERE file_unique_id = %s",
                    (content_id, file_unique_id)
                )
                bid_updated += 1

            await conn.commit()
            return {"fetched": fetched, "product_upserted": upserted, "bid_updated": bid_updated}

        except Exception as e:
            try:
                await conn.rollback()
            except Exception:
                pass
            print(f"[sync_bid_product] ERROR: {e}", flush=True)
            raise
        finally:
            await cls.release(conn, cur)


