# pg_stats_db.py
import asyncpg
import asyncio
from typing import Any, Dict, List,Optional  # ⬅ 新增
from typing import Iterable
import json



class PGStatsDB:
    """
    PostgreSQL 操作层（纯 classmethod 风格）
    与 GroupStatsTracker 的 key 对齐：
      (stat_date, user_id, chat_id, thread_id, msg_type, from_bot, hour)
    """

    pool: asyncpg.Pool | None = None
    _lock = asyncio.Lock()
    _offline_tx_table_inited: bool = False 

    @classmethod
    async def init_pool(cls, dsn: str, min_size: int = 1, max_size: int = 5):
        if cls.pool is not None:
            return cls.pool

        cls.pool = await asyncpg.create_pool(
            dsn=dsn,
            min_size=min_size,
            max_size=max_size
        )
        return cls.pool

    @classmethod
    async def close_pool(cls):
        if cls.pool:
            await cls.pool.close()
            cls.pool = None
    

    @classmethod
    async def ensure_table(cls):
        """
        ✅ PostgreSQL 版 ensure_table（修正 thumbnail_task：移除 MySQL 语法）
        """
        ddls = [
            # 1) 统计表
            """
            CREATE TABLE IF NOT EXISTS tg_msg_stats_daily (
                stat_date  DATE        NOT NULL,
                user_id    BIGINT      NOT NULL,
                chat_id    BIGINT      NOT NULL,
                thread_id  BIGINT      NOT NULL DEFAULT 0,
                msg_type   TEXT        NOT NULL,
                from_bot   BOOLEAN     NOT NULL DEFAULT FALSE,
                hour       SMALLINT    NOT NULL,
                cnt        INTEGER     NOT NULL DEFAULT 0,
                PRIMARY KEY (
                    stat_date, user_id, chat_id, thread_id,
                    msg_type, from_bot, hour
                )
            );
            """,
            """
            CREATE INDEX IF NOT EXISTS idx_stats_chat_date
            ON tg_msg_stats_daily (chat_id, stat_date);
            """,
            """
            CREATE INDEX IF NOT EXISTS idx_stats_user_date
            ON tg_msg_stats_daily (user_id, stat_date);
            """,

            # 2) 精简版 user 表
            """
            CREATE TABLE IF NOT EXISTS "user" (
                user_id BIGINT PRIMARY KEY,
                credit INTEGER DEFAULT 10,
                point INTEGER NOT NULL DEFAULT 0,
                task_award_date DATE DEFAULT NULL,
                task_award_count INTEGER DEFAULT 0,
                last_task_award_at TIMESTAMPTZ DEFAULT NULL,
                first_name text COLLATE pg_catalog."default",
                last_name text COLLATE pg_catalog."default"
            );
            """,

            # 3) 群消息 raw 表（BERTopic 用）
            """
            CREATE TABLE IF NOT EXISTS tg_group_messages_raw (
                chat_id      BIGINT      NOT NULL,
                thread_id    BIGINT      NOT NULL DEFAULT 0,
                message_id   BIGINT      NOT NULL,
                user_id      BIGINT      NOT NULL,
                from_bot     BOOLEAN     NOT NULL DEFAULT FALSE,
                msg_time_utc TIMESTAMPTZ NOT NULL,
                stat_date    DATE        NOT NULL,
                hour         SMALLINT    NOT NULL,
                text         TEXT        NOT NULL,

                topic_id     INTEGER     NULL,
                topic_ver    INTEGER     NOT NULL DEFAULT 1,
                topic_at     TIMESTAMPTZ NULL,

                PRIMARY KEY (chat_id, message_id)
            );
            """,
            """
            CREATE INDEX IF NOT EXISTS idx_raw_chat_date_hour
            ON tg_group_messages_raw (chat_id, stat_date, hour);
            """,
            """
            CREATE INDEX IF NOT EXISTS idx_raw_topic_lookup
            ON tg_group_messages_raw (chat_id, stat_date, hour, topic_id);
            """,

            # 4) 每小时话题摘要表
            """
            CREATE TABLE IF NOT EXISTS tg_group_topics_hourly (
                chat_id     BIGINT   NOT NULL,
                thread_id   BIGINT   NOT NULL DEFAULT 0,
                stat_date   DATE     NOT NULL,
                hour        SMALLINT NOT NULL,
                topic_id    INTEGER  NOT NULL,
                msg_count   INTEGER  NOT NULL DEFAULT 0,
                topic_words TEXT     NOT NULL DEFAULT '',
                keywords    TEXT     NOT NULL DEFAULT '',
                message_ids JSONB    NOT NULL DEFAULT '[]'::jsonb,
                updated_at  TIMESTAMPTZ NOT NULL DEFAULT NOW(),
                PRIMARY KEY (chat_id, thread_id, stat_date, hour, topic_id)
            );
            """,
            """
            CREATE INDEX IF NOT EXISTS idx_topics_chat_date_hour
            ON tg_group_topics_hourly (chat_id, stat_date, hour);
            """,

            # 5) thumbnail_task（原本是 MySQL 写法，这里改为 PG）
            """
            CREATE TABLE IF NOT EXISTS thumbnail_task (
                id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,

                file_unique_id VARCHAR(100) NOT NULL,
                file_type VARCHAR(20) NOT NULL,          -- video
                doc_id BIGINT NOT NULL,
                access_hash BIGINT NOT NULL,
                file_reference BYTEA NULL,
                mime_type VARCHAR(100) NULL,
                file_name VARCHAR(255) NULL,
                file_size BIGINT NULL,

                assigned_bot_name VARCHAR(30) NULL,
                sent_chat_id BIGINT NULL,
                sent_message_id BIGINT NULL,

                -- bot 回传缩图（通常是 photo）
                thumb_doc_id BIGINT NULL,
                thumb_access_hash BIGINT NULL,
                thumb_file_reference BYTEA NULL,

                recv_chat_id BIGINT NULL,
                recv_message_id BIGINT NULL,
                recv_at TIMESTAMPTZ NULL,

                status TEXT NOT NULL DEFAULT 'pending'
                    CHECK (status IN ('pending','working','failed','completed')),

                sent_at TIMESTAMPTZ NULL,
                completed_at TIMESTAMPTZ NULL,
                updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
                created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
            );
            """,
            """
            CREATE UNIQUE INDEX IF NOT EXISTS uq_thumb_file_unique_id
            ON thumbnail_task (file_unique_id);
            """,
            """
            CREATE INDEX IF NOT EXISTS idx_thumb_status_created
            ON thumbnail_task (status, created_at);
            """,
            """
            CREATE INDEX IF NOT EXISTS idx_thumb_bot_status
            ON thumbnail_task (assigned_bot_name, status, updated_at);
            """,
            """
            CREATE TABLE IF NOT EXISTS board (
                board_id integer NOT NULL GENERATED BY DEFAULT AS IDENTITY,
                board_key varchar(15) NOT NULL,
                chat_id bigint NOT NULL DEFAULT 0,
                message_thread_id integer NOT NULL DEFAULT 0,
                board_title varchar(100) NOT NULL,
                board_description text NOT NULL,
                button varchar(100),
                icon_custom_emoji_id bigint,
                file_type varchar(10),
                file_unique_id varchar(30) NOT NULL,
                file_id varchar(100) NOT NULL,
                bot varchar(50) NOT NULL,
                post_message_id integer,
                funds integer NOT NULL DEFAULT 0,
                pre_funds integer NOT NULL DEFAULT 0,
                manager_id varchar(100),

                CONSTRAINT board_pkey PRIMARY KEY (board_id),
                CONSTRAINT board_board_key_key UNIQUE (board_key)
            );
            """,
            """
            CREATE TABLE IF NOT EXISTS task_rec (
            task_id        integer GENERATED BY DEFAULT AS IDENTITY,
            task_title     varchar(30)  NOT NULL,
            task_value     text         NULL,
            task_time      bigint       NULL,     -- 原 int(13)，建议用 bigint 存 epoch seconds
            task_interval  integer      NOT NULL,
            task_exec      text         NULL,
            CONSTRAINT task_rec_pkey PRIMARY KEY (task_id)
            );
            """,


        ]

        async with cls._lock:
            if cls.pool is None:
                raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 init_pool()")
            async with cls.pool.acquire() as conn:
                for ddl in ddls:
                    await conn.execute(ddl)




    @classmethod
    async def upsert_daily_counts(cls, items: list[tuple[tuple, int]]):
        """
        items:
          [ ((stat_date,user_id,chat_id,thread_id,msg_type,from_bot,hour), cnt), ... ]
        """
        if not items:
            return
       
        sql = """
        INSERT INTO tg_msg_stats_daily
            (stat_date, user_id, chat_id, thread_id, msg_type, from_bot, hour, cnt)
        VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
        ON CONFLICT (
            stat_date, user_id, chat_id, thread_id,
            msg_type, from_bot, hour
        )
        DO UPDATE SET cnt = tg_msg_stats_daily.cnt + EXCLUDED.cnt;
        """

        async with cls._lock:
            async with cls.pool.acquire() as conn:
                async with conn.transaction():
                    for (key, c) in items:
                        (
                            stat_date, user_id, chat_id,
                            thread_id, msg_type, from_bot, hour
                        ) = key

                        await conn.execute(
                            sql,
                            stat_date, user_id, chat_id,
                            thread_id, msg_type, from_bot, hour, c
                        )

    # ================== 离线交易队列表 ==================

    @classmethod
    async def ensure_offline_tx_table(cls):
        """
        建立离线交易队列表 offline_transaction_queue
        需要在 init_pool(dsn) 之后调用一次。
        """
        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 PGStatsDB.init_pool(dsn)")

        # 避免每次都重建
        if cls._offline_tx_table_inited:
            return

        ddl = """
        CREATE TABLE IF NOT EXISTS offline_transaction_queue (
            id                      BIGSERIAL PRIMARY KEY,
            sender_id               BIGINT      NOT NULL,
            receiver_id             BIGINT      NULL,
            transaction_type        TEXT        NOT NULL,
            transaction_description TEXT        NOT NULL,
            sender_fee              INTEGER     NOT NULL,
            receiver_fee            INTEGER     NOT NULL,
            created_at              TIMESTAMPTZ NOT NULL DEFAULT NOW(),
            processed               BOOLEAN     NOT NULL DEFAULT FALSE,
            processed_at            TIMESTAMPTZ NULL,
            last_error              TEXT        NULL
        );
        """
        async with cls.pool.acquire() as conn:
            await conn.execute(ddl)

        cls._offline_tx_table_inited = True

    @classmethod
    async def record_offline_transaction(cls, transaction_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        MySQL 不可用时的降级方案：
        1. 先在 PostgreSQL 的 "user" 表中扣/加 point（以 PG 当前的 point 为准）
        2. 把整笔交易写到 offline_transaction_queue，等 MySQL 恢复后再回放

        预期 transaction_data 结构：
        {
            "sender_id": int,
            "receiver_id": int,
            "transaction_type": str,
            "transaction_description": str,
            "sender_fee": int,    # 通常是负数
            "receiver_fee": int,  # 通常是正数
            ...
        }
        """
        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 PGStatsDB.init_pool(dsn)")

        # 确保离线交易表存在
        await cls.ensure_offline_tx_table()

        sender_id = int(transaction_data["sender_id"])
        receiver_id = int(transaction_data.get("receiver_id") or 0)
        sender_fee = int(transaction_data["sender_fee"])
        receiver_fee = int(transaction_data["receiver_fee"])
        tx_type = transaction_data["transaction_type"]
        tx_desc = transaction_data["transaction_description"]

        async with cls.pool.acquire() as conn:
            try:
                async with conn.transaction():
                    # 1) 锁定 sender 的 point
                    row = await conn.fetchrow(
                        'SELECT point FROM "user" WHERE user_id = $1 FOR UPDATE',
                        sender_id,
                    )
                    if not row:
                        return {
                            "ok": "",
                            "status": "pg_user_not_found",
                            "transaction_data": transaction_data,
                        }

                    current_point = int(row["point"] or 0)
                    if current_point < abs(sender_fee):
                        return {
                            "ok": "",
                            "status": "pg_insufficient_funds",
                            "transaction_data": transaction_data,
                            "user_info": {"point": current_point},
                        }

                    # 2) 扣 sender 点数（sender_fee 一般是负数）
                    await conn.execute(
                        'UPDATE "user" SET point = point + $1 WHERE user_id = $2',
                        sender_fee,
                        sender_id,
                    )

                    # 3) 加 receiver 点数（如果有）
                    if receiver_id:
                        await conn.execute(
                            'UPDATE "user" SET point = point + $1 WHERE user_id = $2',
                            receiver_fee,
                            receiver_id,
                        )

                    # 4) 写入离线交易队列
                    row = await conn.fetchrow(
                        """
                        INSERT INTO offline_transaction_queue (
                            sender_id,
                            receiver_id,
                            transaction_type,
                            transaction_description,
                            sender_fee,
                            receiver_fee
                        )
                        VALUES ($1, $2, $3, $4, $5, $6)
                        RETURNING id, created_at
                        """,
                        sender_id,
                        receiver_id if receiver_id != 0 else None,
                        tx_type,
                        tx_desc,
                        sender_fee,
                        receiver_fee,
                    )

                print(
                    f'✅ [PG offline] 已记录离线交易 id={row["id"]} type={tx_type} desc={tx_desc}',
                    flush=True,
                )
                return {
                    "ok": "1",
                    "status": "offline_queue",
                    "offline_id": int(row["id"]),
                    "transaction_data": transaction_data,
                }

            except Exception as e:
                print(f"❌ [PG offline] record_offline_transaction 出错: {e}", flush=True)
                return {
                    "ok": "",
                    "status": "pg_offline_error",
                    "error": str(e),
                    "transaction_data": transaction_data,
                }

 

    @classmethod
    async def find_transaction_by_description(cls, desc: str) -> Optional[Dict[str, Any]]:
        """
        根据 transaction_description 在 PostgreSQL 中查询一笔交易纪录。

        目前仅查询 offline_transaction_queue：
        - 用于 MySQL 挂掉、交易改记到 PG 离线队列时的“查重”/确认用途
        - 语义上等价于 MySQLPool.find_transaction_by_description，但数据来源不同

        :param desc: 例如 "chat_id message_id"
        :return: dict | None
        """
        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 PGStatsDB.init_pool(dsn)")

       

        async with cls.pool.acquire() as conn:
            try:
                row = await conn.fetchrow(
                    """
                    SELECT
                        id,
                        sender_id,
                        receiver_id,
                        transaction_type,
                        transaction_description,
                        sender_fee,
                        receiver_fee,
                        created_at,
                        processed,
                        processed_at,
                        last_error
                    FROM offline_transaction_queue
                    WHERE transaction_description = $1
                    ORDER BY id DESC
                    LIMIT 1
                    """,
                    desc,
                )
                # 与 MySQL 版行为对齐：查不到就回 None，查到就回 dict
                return dict(row) if row else None

            except Exception as e:
                print(f"⚠️ PGStatsDB.find_transaction_by_description 出错: {e}", flush=True)
                return None

   

    @classmethod
    async def sync_user_from_mysql(cls, max_batch: int = 1000) -> int:
        """
        单向同步：
        - 从 MySQL telebot.user 抓出按 update_time 排序的最多 max_batch 笔
        - 把 user_id / credit / point / task_award_date / task_award_count / last_task_award_at
          upsert 到 PostgreSQL 的 "user" 表

        注意：
        - 只负责 MySQL → PostgreSQL，不会反向改 MySQL
        - 需要外部先调用 MySQLPool.init_pool / PGStatsDB.init_pool / PGStatsDB.ensure_table()
        """
        # 延迟引入，避免循环依赖
        from lz_mysql import MySQLPool

        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 PGStatsDB.init_pool()")

        # 1) 从 MySQL 抓最近更新的 user 记录
        await MySQLPool.ensure_pool()
        conn_mysql, cur_mysql = await MySQLPool.get_conn_cursor()
        try:
            sql = (
                "SELECT user_id, credit, point, task_award_date, "
                "       task_award_count, last_task_award_at "
                "FROM user "
                "ORDER BY update_time DESC "
                "LIMIT %s"
            )
            await cur_mysql.execute(sql, (max_batch,))
            rows = await cur_mysql.fetchall()
        finally:
            await MySQLPool.release(conn_mysql, cur_mysql)

        if not rows:
            print("✅ sync_user_from_mysql: MySQL 无更新记录可同步。", flush=True)
            return 0

        # 2) 组装参数列表，写入 PostgreSQL
        records: List[tuple] = []
        for row in rows:
            # aiomysql 一般是 dict-like row
            user_id = int(row["user_id"])
            credit = row.get("credit", 10)
            point = row.get("point", 0)
            task_award_date = row.get("task_award_date")
            task_award_count = row.get("task_award_count", 0)
            last_task_award_at = row.get("last_task_award_at")

            records.append(
                (
                    user_id,
                    int(credit) if credit is not None else 10,
                    int(point) if point is not None else 0,
                    task_award_date,
                    int(task_award_count) if task_award_count is not None else 0,
                    last_task_award_at,
                )
            )

        async with cls.pool.acquire() as conn_pg:
            sql_pg = """
                INSERT INTO "user" (
                    user_id,
                    credit,
                    point,
                    task_award_date,
                    task_award_count,
                    last_task_award_at
                )
                VALUES ($1, $2, $3, $4, $5, $6)
                ON CONFLICT (user_id) DO UPDATE SET
                    credit = EXCLUDED.credit,
                    point  = EXCLUDED.point,
                    task_award_date = EXCLUDED.task_award_date,
                    task_award_count = EXCLUDED.task_award_count,
                    last_task_award_at = EXCLUDED.last_task_award_at
            """
            async with conn_pg.transaction():
                await conn_pg.executemany(sql_pg, records)

        print(f"✅ sync_user_from_mysql: 已同步 {len(records)} 笔 user 记录到 PostgreSQL。", flush=True)
        return len(records)


    @classmethod
    async def sync_board_from_mysql(cls) -> int:
        """
        ✅ 单向同步（覆盖模式）：
        - 从 MySQL telebot.board 全量抓取
        - PostgreSQL public.board 先 TRUNCATE 再全量写入
        - 最终 PG 的 board 与 MySQL 完全一致（包含删除掉 PG 多余旧数据）

        注意：
        - 需要外部先调用 MySQLPool.init_pool / PGStatsDB.init_pool / PGStatsDB.ensure_table()
        - 假设 PG 的 board 没有被其它表做 FK 约束（你当前 schema 看起来是独立表）
        """
        from lz_mysql import MySQLPool

        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 PGStatsDB.init_pool()")

        # 1) MySQL 全量抓 board
        await MySQLPool.ensure_pool()
        conn_mysql, cur_mysql = await MySQLPool.get_conn_cursor()
        try:
            sql = """
                SELECT
                    board_id,
                    board_key,
                    chat_id,
                    message_thread_id,
                    board_title,
                    board_description,
                    button,
                    icon_custom_emoji_id,
                    file_type,
                    file_unique_id,
                    file_id,
                    bot,
                    post_message_id,
                    funds,
                    pre_funds,
                    manager_id
                FROM board
                ORDER BY board_id ASC
            """
            await cur_mysql.execute(sql)
            rows = await cur_mysql.fetchall()
        finally:
            await MySQLPool.release(conn_mysql, cur_mysql)

        if not rows:
            # 覆盖语义：MySQL 没资料 => PG 也应该清空
            async with cls.pool.acquire() as conn_pg:
                async with conn_pg.transaction():
                    await conn_pg.execute('TRUNCATE TABLE board RESTART IDENTITY;')
            print("✅ sync_board_from_mysql: MySQL board 为空，已清空 PostgreSQL board。", flush=True)
            return 0

        # 2) 组装写入记录
        records = []
        for r in rows:
            # aiomysql dict-like row
            records.append(
                (
                    int(r["board_id"]),
                    r["board_key"],
                    int(r.get("chat_id") or 0),
                    int(r.get("message_thread_id") or 0),
                    r["board_title"],
                    r["board_description"],
                    r.get("button"),
                    (int(r["icon_custom_emoji_id"]) if r.get("icon_custom_emoji_id") is not None else None),
                    r.get("file_type"),
                    r["file_unique_id"],
                    r["file_id"],
                    r["bot"],
                    (int(r["post_message_id"]) if r.get("post_message_id") is not None else None),
                    int(r.get("funds") or 0),
                    int(r.get("pre_funds") or 0),
                    r.get("manager_id"),
                )
            )

        insert_sql = """
            INSERT INTO board (
                board_id,
                board_key,
                chat_id,
                message_thread_id,
                board_title,
                board_description,
                button,
                icon_custom_emoji_id,
                file_type,
                file_unique_id,
                file_id,
                bot,
                post_message_id,
                funds,
                pre_funds,
                manager_id
            )
            VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16);
        """

        async with cls.pool.acquire() as conn_pg:
            async with conn_pg.transaction():
                # 覆盖：先清空再写入
                await conn_pg.execute('TRUNCATE TABLE board RESTART IDENTITY;')
                await conn_pg.executemany(insert_sql, records)

                # 让 identity/sequence 跟上最大 board_id（保险起见）
                await conn_pg.execute(
                    """
                    SELECT setval(
                        pg_get_serial_sequence('board','board_id'),
                        (SELECT COALESCE(MAX(board_id), 1) FROM board),
                        TRUE
                    );
                    """
                )

        print(f"✅ sync_board_from_mysql: 已覆盖同步 {len(records)} 笔 board 记录到 PostgreSQL。", flush=True)
        return len(records)



    # （写入原始语料，含 message_id）
    @classmethod
    async def upsert_raw_messages(cls, rows: list[dict]):
        """
        rows: [
          {
            "chat_id": int,
            "thread_id": int,
            "message_id": int,
            "user_id": int,
            "from_bot": bool,
            "msg_time_utc": datetime,   # msg.date
            "stat_date": date,          # msg.date +8h 的 date
            "hour": int,                # msg.date +8h 的 hour
            "text": str,
          }, ...
        ]
        """
        if not rows:
            return

        sql = """
        INSERT INTO tg_group_messages_raw
            (chat_id, thread_id, message_id, user_id, from_bot,
             msg_time_utc, stat_date, hour, text)
        VALUES
            ($1,$2,$3,$4,$5,$6,$7,$8,$9)
        ON CONFLICT (chat_id, message_id)
        DO UPDATE SET
            thread_id    = EXCLUDED.thread_id,
            user_id      = EXCLUDED.user_id,
            from_bot     = EXCLUDED.from_bot,
            msg_time_utc = EXCLUDED.msg_time_utc,
            stat_date    = EXCLUDED.stat_date,
            hour         = EXCLUDED.hour,
            text         = EXCLUDED.text;
        """

        async with cls._lock:
            if cls.pool is None:
                raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 init_pool()")
            async with cls.pool.acquire() as conn:
                async with conn.transaction():
                    for r in rows:
                        await conn.execute(
                            sql,
                            int(r["chat_id"]),
                            int(r.get("thread_id") or 0),
                            int(r["message_id"]),
                            int(r["user_id"]),
                            bool(r.get("from_bot", False)),
                            r["msg_time_utc"],
                            r["stat_date"],
                            int(r["hour"]),
                            r["text"],
                        )


    @classmethod
    async def fetch_hour_texts(cls, chat_id: int, stat_date, hour: int, thread_id: int = 0, min_len: int = 3):
        sql = """
        SELECT message_id, text
        FROM tg_group_messages_raw
        WHERE chat_id=$1 AND stat_date=$2 AND hour=$3 AND thread_id=$4
          AND from_bot=FALSE
          AND length(text) >= $5
        ORDER BY message_id ASC
        """
        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 init_pool()")
        async with cls.pool.acquire() as conn:
            rows = await conn.fetch(sql, int(chat_id), stat_date, int(hour), int(thread_id), int(min_len))
            return [{"message_id": int(r["message_id"]), "text": r["text"]} for r in rows]

    @classmethod
    async def update_message_topics(cls, chat_id: int, stat_date, hour: int, mapping: dict[int, int], thread_id: int = 0, topic_ver: int = 1):
        """
        mapping: { message_id: topic_id, ... }
        """
        if not mapping:
            return

        sql = """
        UPDATE tg_group_messages_raw
        SET topic_id=$5, topic_ver=$6, topic_at=NOW()
        WHERE chat_id=$1 AND stat_date=$2 AND hour=$3 AND thread_id=$4 AND message_id=$7
        """
        async with cls._lock:
            if cls.pool is None:
                raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 init_pool()")
            async with cls.pool.acquire() as conn:
                async with conn.transaction():
                    for mid, tid in mapping.items():
                        await conn.execute(
                            sql,
                            int(chat_id), stat_date, int(hour), int(thread_id),
                            int(tid), int(topic_ver), int(mid)
                        )

    @classmethod
    async def upsert_topics_hourly(
        cls,
        chat_id: int,
        thread_id: int,
        stat_date,
        hour: int,
        topics: list[dict],
    ):
        """
        topics: [
          {
            "topic_id": int,
            "msg_count": int,
            "topic_words": str,     # BERTopic 的词（可选）
            "keywords": str,        # pke_zh 精炼短语（建议逗号分隔）
            "message_ids": list[int]  # 代表消息 ID（证据链）
          }, ...
        ]
        """
        if not topics:
            return

        sql = """
        INSERT INTO tg_group_topics_hourly
            (chat_id, thread_id, stat_date, hour, topic_id, msg_count, topic_words, keywords, message_ids, updated_at)
        VALUES
            ($1,$2,$3,$4,$5,$6,$7,$8,$9,NOW())
        ON CONFLICT (chat_id, thread_id, stat_date, hour, topic_id)
        DO UPDATE SET
            msg_count   = EXCLUDED.msg_count,
            topic_words = EXCLUDED.topic_words,
            keywords    = EXCLUDED.keywords,
            message_ids = EXCLUDED.message_ids,
            updated_at  = NOW();
        """

        async with cls._lock:
            if cls.pool is None:
                raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 init_pool()")
            async with cls.pool.acquire() as conn:
                async with conn.transaction():
                    for t in topics:
                        await conn.execute(
                            sql,
                            int(chat_id),
                            int(thread_id or 0),
                            stat_date,
                            int(hour),
                            int(t["topic_id"]),
                            int(t.get("msg_count", 0)),
                            t.get("topic_words", "") or "",
                            t.get("keywords", "") or "",
                            json.dumps([int(x) for x in (t.get("message_ids") or [])], ensure_ascii=False),
                        )

    @classmethod
    async def get_topics_hourly(cls, chat_id: int, stat_date, hour: int, thread_id: int = 0, limit: int = 10):
        sql = """
        SELECT topic_id, msg_count, keywords, topic_words, message_ids
        FROM tg_group_topics_hourly
        WHERE chat_id=$1 AND stat_date=$2 AND hour=$3 AND thread_id=$4
        ORDER BY msg_count DESC
        LIMIT $5
        """
        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 init_pool()")
        async with cls.pool.acquire() as conn:
            rows = await conn.fetch(sql, int(chat_id), stat_date, int(hour), int(thread_id), int(limit))
            return [dict(r) for r in rows]

    @classmethod
    async def get_topic_all_message_ids(cls, chat_id: int, stat_date, hour: int, topic_id: int, thread_id: int = 0, limit: int = 500):
        """
        反查：某小时某 topic 的所有 message_id（不仅是代表 message_ids）
        """
        sql = """
        SELECT message_id
        FROM tg_group_messages_raw
        WHERE chat_id=$1 AND stat_date=$2 AND hour=$3 AND thread_id=$4 AND topic_id=$5
        ORDER BY message_id ASC
        LIMIT $6
        """
        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 init_pool()")
        async with cls.pool.acquire() as conn:
            rows = await conn.fetch(sql, int(chat_id), stat_date, int(hour), int(thread_id), int(topic_id), int(limit))
            return [int(r["message_id"]) for r in rows]

    # ================== 预览图 ==================
    # ===== thumbnail_task (PostgreSQL) =====

    @classmethod
    async def insert_thumbnail_task_if_absent(
        cls,
        file_unique_id: str,
        file_type: str,
        doc_id: int,
        access_hash: int,
        file_reference: bytes | None,
        mime_type: str | None,
        file_name: str | None,
        file_size: int | None,
    ) -> bool:
        """
        若 file_unique_id 已存在则不插入；不存在则插入 pending。
        回传 True=新增成功，False=已存在或未新增。
        """
        sql = """
        INSERT INTO thumbnail_task
            (file_unique_id, file_type, doc_id, access_hash, file_reference, mime_type, file_name, file_size, status)
        VALUES
            ($1, $2, $3, $4, $5, $6, $7, $8, 'pending')
        ON CONFLICT (file_unique_id) DO NOTHING
        RETURNING id;
        """
        async with cls.pool.acquire() as conn:
            row = await conn.fetchrow(
                sql,
                file_unique_id, file_type, doc_id, access_hash,
                file_reference, mime_type, file_name, file_size
            )
        return row is not None

    @classmethod
    async def get_working_counts(cls, bot_names: List[str]) -> Dict[str, int]:
        """
        回传 {bot_name: working_count}，用于判断 bot 是否在 working。
        """
        if not bot_names:
            return {}
        sql = """
        SELECT assigned_bot_name, COUNT(*)::int AS cnt
        FROM thumbnail_task
        WHERE status='working'
          AND assigned_bot_name = ANY($1::text[])
        GROUP BY assigned_bot_name;
        """
        async with cls.pool.acquire() as conn:
            rows = await conn.fetch(sql, bot_names)
        return {r["assigned_bot_name"]: r["cnt"] for r in rows}

    @classmethod
    async def lock_one_pending_task_for_bot(cls, bot_name: str) -> Optional[Dict[str, Any]]:
        """
        以 PG 的 SKIP LOCKED 抢 1 笔 pending -> working，并 RETURNING 整行。
        这比你现有的 “先 SELECT 再 UPDATE” 更抗并发、更不容易抢重。
        """
        sql = """
        WITH picked AS (
            SELECT id
            FROM thumbnail_task
            WHERE status='pending'
            ORDER BY created_at ASC
            FOR UPDATE SKIP LOCKED
            LIMIT 1
        )
        UPDATE thumbnail_task t
        SET status='working',
            assigned_bot_name=$1,
            updated_at=NOW()
        FROM picked
        WHERE t.id = picked.id
        RETURNING t.*;
        """
        async with cls.pool.acquire() as conn:
            async with conn.transaction():
                row = await conn.fetchrow(sql, bot_name)
        return dict(row) if row else None

    @classmethod
    async def update_task_sent_info(cls, file_unique_id: str, chat_id: int, message_id: int) -> None:
        sql = """
        UPDATE thumbnail_task
        SET sent_chat_id=$2,
            sent_message_id=$3,
            sent_at=NOW(),
            updated_at=NOW()
        WHERE file_unique_id=$1;
        """
        async with cls.pool.acquire() as conn:
            await conn.execute(sql, file_unique_id, int(chat_id), int(message_id))

    @classmethod
    async def complete_task_by_reply(
        cls,
        bot_name: str,
        chat_id: int,
        reply_to_msg_id: int,
        thumb_doc_id: int,
        thumb_access_hash: int,
        thumb_file_reference: bytes | None,
        recv_message_id: int,
    ) -> bool:
        """
        bot 用 photo 回复派工消息：
        用 (assigned_bot_name + sent_chat_id + sent_message_id + status=working) 精确定位任务并完成。
        """
        sql = """
        UPDATE thumbnail_task
        SET status='completed',
            completed_at=NOW(),
            updated_at=NOW(),
            thumb_doc_id=$4,
            thumb_access_hash=$5,
            thumb_file_reference=$6,
            recv_chat_id=$2,
            recv_message_id=$7,
            recv_at=NOW()
        WHERE status='working'
          AND assigned_bot_name=$1
          AND sent_chat_id=$2
          AND sent_message_id=$3
        RETURNING id;
        """
        async with cls.pool.acquire() as conn:
            row = await conn.fetchrow(
                sql,
                bot_name, int(chat_id), int(reply_to_msg_id),
                int(thumb_doc_id), int(thumb_access_hash),
                thumb_file_reference, int(recv_message_id)
            )
        return row is not None



    @classmethod
    async def get_users_missing_names(cls, user_ids: Iterable[int]) -> list[int]:
        ids = [int(x) for x in user_ids if str(x).strip()]
        if not ids:
            return []
        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 init_pool()")

        sql = """
        SELECT user_id
        FROM "user"
        WHERE user_id = ANY($1::bigint[])
          AND (first_name IS NULL OR first_name = '')
        """
        async with cls.pool.acquire() as conn:
            rows = await conn.fetch(sql, ids)
        return [int(r["user_id"]) for r in rows]

    @classmethod
    async def upsert_user_profile(cls, user_id: int, first_name: Optional[str], last_name: Optional[str]) -> None:
        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 init_pool()")

        sql = """
        INSERT INTO "user" (user_id, first_name, last_name)
        VALUES ($1, $2, $3)
        ON CONFLICT (user_id) DO UPDATE SET
            first_name = COALESCE(EXCLUDED.first_name, "user".first_name),
            last_name  = COALESCE(EXCLUDED.last_name,  "user".last_name);
        """
        async with cls.pool.acquire() as conn:
            await conn.execute(sql, int(user_id), first_name, last_name)

    @classmethod
    async def get_board_thread_daily_stats(
        cls,
        stat_date,
        tg_chat_id: int,
        include_bots: bool = False,
    ) -> list[dict[str, Any]]:
        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 init_pool()")

        sql = """
        WITH b AS (
            SELECT
                board_id,
                board_title,
                funds,
                message_thread_id::bigint AS thread_id,
                manager_id,
                CAST('-100' || chat_id::text AS bigint) AS tg_chat_id
            FROM board
            WHERE CAST('-100' || chat_id::text AS bigint) = $1
        ),
        msg AS (
            SELECT
                r.thread_id,
                COUNT(*)::int AS msg_count
            FROM tg_group_messages_raw r
            WHERE r.chat_id = $1
              AND r.stat_date = $2
              AND ($3::boolean = TRUE OR r.from_bot = FALSE)
            GROUP BY r.thread_id
        ),
        mgr AS (
            SELECT
                b.board_id,
                NULLIF(trim(x), '')::bigint AS manager_user_id
            FROM b
            LEFT JOIN LATERAL unnest(string_to_array(COALESCE(b.manager_id, ''), ';')) AS x ON TRUE
        ),
        mgr_cnt AS (
            SELECT
                m.board_id,
                m.manager_user_id,
                COUNT(r.*)::int AS cnt
            FROM mgr m
            LEFT JOIN tg_group_messages_raw r
              ON r.chat_id = $1
             AND r.stat_date = $2
             AND r.thread_id = (SELECT thread_id FROM b WHERE b.board_id = m.board_id)
             AND r.user_id = m.manager_user_id
             AND ($3::boolean = TRUE OR r.from_bot = FALSE)
            WHERE m.manager_user_id IS NOT NULL
            GROUP BY m.board_id, m.manager_user_id
        ),
        mgr_named AS (
            SELECT
                mc.board_id,
                mc.manager_user_id,
                mc.cnt,
                u.first_name,
                u.last_name
            FROM mgr_cnt mc
            LEFT JOIN "user" u ON u.user_id = mc.manager_user_id
        )
        SELECT
            b.board_id,
            b.board_title,
            b.thread_id,
            COALESCE(msg.msg_count, 0) AS msg_count,
            b.funds,
            COALESCE(
                jsonb_agg(
                    jsonb_build_object(
                        'manager_user_id', mn.manager_user_id,
                        'first_name', COALESCE(mn.first_name, ''),
                        'last_name',  COALESCE(mn.last_name,  ''),
                        'manager_msg_count', mn.cnt
                    )
                ) FILTER (WHERE mn.manager_user_id IS NOT NULL),
                '[]'::jsonb
            ) AS managers
        FROM b
        LEFT JOIN msg ON msg.thread_id = b.thread_id
        LEFT JOIN mgr_named mn ON mn.board_id = b.board_id
        GROUP BY b.board_id, b.board_title, b.thread_id, msg.msg_count, b.funds
        ORDER BY b.thread_id ASC;
        """

        async with cls.pool.acquire() as conn:
            rows = await conn.fetch(sql, int(tg_chat_id), stat_date, bool(include_bots))

        # asyncpg Record -> dict，并把 jsonb 转 python
        out: list[dict[str, Any]] = []
        for r in rows:
            d = dict(r)
            # d["managers"] 已是可用结构（asyncpg 对 jsonb 通常会返回 python 对象；若是 str 再 json.loads）
            if isinstance(d.get("managers"), str):
                import json
                d["managers"] = json.loads(d["managers"])
            out.append(d)
        return out




    @classmethod
    async def get_board_thread_daily_stats_range(
        cls,
        stat_date_from,
        stat_date_to,
        tg_chat_id: int,
        include_bots: bool = False,
    ) -> list[dict[str, Any]]:
        """
        统计区间 [stat_date_from, stat_date_to] 内，每日每板块：
        - board_title
        - msg_count（当日该 thread 的总发言数）
        - funds
        - managers（逐个版主的当日发言数 + 名字）
        且：即使某板块当天没人发言，也会列出来（msg_count=0）。
        """

        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 init_pool()")

        # 容错：from/to 颠倒时自动交换
        if stat_date_from and stat_date_to and stat_date_from > stat_date_to:
            stat_date_from, stat_date_to = stat_date_to, stat_date_from

        sql = """
        WITH b AS (
            SELECT
                board_id,
                board_title,
                funds,
                message_thread_id::bigint AS thread_id,
                manager_id,
                CAST('-100' || chat_id::text AS bigint) AS tg_chat_id
            FROM board
            WHERE CAST('-100' || chat_id::text AS bigint) = $1
        ),
        d AS (
            SELECT gs::date AS stat_date
            FROM generate_series($2::date, $3::date, interval '1 day') AS gs
        ),
        base AS (
            -- ✅ 每一天 × 每一个 board，确保“当天没人发言也列出来”
            SELECT
                d.stat_date,
                b.board_id,
                b.board_title,
                b.thread_id,
                b.funds,
                b.manager_id
            FROM d
            CROSS JOIN b
        ),
        msg AS (
            SELECT
                r.stat_date,
                r.thread_id,
                COUNT(*)::int AS msg_count
            FROM tg_group_messages_raw r
            WHERE r.chat_id = $1
              AND r.stat_date BETWEEN $2 AND $3
              AND ($4::boolean = TRUE OR r.from_bot = FALSE)
            GROUP BY r.stat_date, r.thread_id
        ),
        mgr AS (
            -- 每个 board 拆出多个 manager_user_id
            SELECT
                b.board_id,
                NULLIF(trim(x), '')::bigint AS manager_user_id
            FROM b
            LEFT JOIN LATERAL unnest(string_to_array(COALESCE(b.manager_id, ''), ';')) AS x ON TRUE
        ),
        mgr_base AS (
            -- ✅ 每一天 × 每个 board 的每个 manager，确保“版主当天没发言也列出来”
            SELECT
                d.stat_date,
                m.board_id,
                m.manager_user_id
            FROM d
            JOIN mgr m ON TRUE
            WHERE m.manager_user_id IS NOT NULL
        ),
        mgr_cnt AS (
            SELECT
                mb.stat_date,
                mb.board_id,
                mb.manager_user_id,
                COUNT(r.message_id)::int AS cnt
            FROM mgr_base mb
            LEFT JOIN b
                ON b.board_id = mb.board_id
            LEFT JOIN tg_group_messages_raw r
                ON r.chat_id = $1
               AND r.stat_date = mb.stat_date
               AND r.thread_id = b.thread_id
               AND r.user_id = mb.manager_user_id
               AND ($4::boolean = TRUE OR r.from_bot = FALSE)
            GROUP BY mb.stat_date, mb.board_id, mb.manager_user_id
        ),
        mgr_named AS (
            SELECT
                mc.stat_date,
                mc.board_id,
                mc.manager_user_id,
                mc.cnt,
                u.first_name,
                u.last_name
            FROM mgr_cnt mc
            LEFT JOIN "user" u ON u.user_id = mc.manager_user_id
        )
        SELECT
            base.stat_date,
            base.board_id,
            base.board_title,
            base.thread_id,
            COALESCE(msg.msg_count, 0) AS msg_count,
            base.funds,
            COALESCE(
                jsonb_agg(
                    jsonb_build_object(
                        'manager_user_id', mn.manager_user_id,
                        'first_name', COALESCE(mn.first_name, ''),
                        'last_name',  COALESCE(mn.last_name,  ''),
                        'manager_msg_count', mn.cnt
                    )
                    ORDER BY mn.manager_user_id
                ) FILTER (WHERE mn.manager_user_id IS NOT NULL),
                '[]'::jsonb
            ) AS managers
        FROM base
        LEFT JOIN msg
            ON msg.stat_date = base.stat_date
           AND msg.thread_id = base.thread_id
        LEFT JOIN mgr_named mn
            ON mn.stat_date = base.stat_date
           AND mn.board_id = base.board_id
        GROUP BY
            base.stat_date, base.board_id, base.board_title, base.thread_id, msg.msg_count, base.funds
        ORDER BY
            base.stat_date ASC, base.thread_id ASC;
        """

        async with cls.pool.acquire() as conn:
            rows = await conn.fetch(
                sql,
                int(tg_chat_id),
                stat_date_from,
                stat_date_to,
                bool(include_bots),
            )

        out: list[dict[str, Any]] = []
        for r in rows:
            d = dict(r)
            # asyncpg 对 jsonb 通常直接给 python 对象；若是 str 则 loads
            if isinstance(d.get("managers"), str):
                import json
                d["managers"] = json.loads(d["managers"])
            out.append(d)
        return out




    @classmethod
    async def get_board_thread_stats_range_sum(
        cls,
        stat_date_from,
        stat_date_to,
        tg_chat_id: int,
        include_bots: bool = False,
    ) -> list[dict[str, Any]]:
        """
        统计区间 [stat_date_from, stat_date_to] 内：
        - 每个板块(thread) 的总发言数（不分天）
        - 板块 funds
        - 多个版主各自的区间发言总数 + 名字
        - 即使区间内 0 发言，也会列出
        - 结果按 msg_count DESC 排序
        """

        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化，请先调用 init_pool()")

        # 容错：from/to 反了就交换
        if stat_date_from and stat_date_to and stat_date_from > stat_date_to:
            stat_date_from, stat_date_to = stat_date_to, stat_date_from

        sql = """
        WITH b AS (
            -- 所有板块
            SELECT
                board_id,
                board_title,
                funds,
                message_thread_id::bigint AS thread_id,
                manager_id,
                CAST('-100' || chat_id::text AS bigint) AS tg_chat_id
            FROM board
            WHERE CAST('-100' || chat_id::text AS bigint) = $1
        ),
        msg AS (
            -- 区间内，每个 thread 的总发言数
            SELECT
                r.thread_id,
                COUNT(*)::int AS msg_count
            FROM tg_group_messages_raw r
            WHERE r.chat_id = $1
              AND r.stat_date BETWEEN $2 AND $3
              AND ($4::boolean = TRUE OR r.from_bot = FALSE)
            GROUP BY r.thread_id
        ),
        mgr AS (
            -- 拆出每个板块的 manager_user_id
            SELECT
                b.board_id,
                b.thread_id,
                NULLIF(trim(x), '')::bigint AS manager_user_id
            FROM b
            LEFT JOIN LATERAL unnest(string_to_array(COALESCE(b.manager_id, ''), ';')) AS x ON TRUE
        ),
        mgr_cnt AS (
            -- 区间内，每个 manager 在每个板块的发言总数
            SELECT
                m.board_id,
                m.manager_user_id,
                COUNT(r.message_id)::int AS cnt
            FROM mgr m
            LEFT JOIN tg_group_messages_raw r
              ON r.chat_id = $1
             AND r.stat_date BETWEEN $2 AND $3
             AND r.thread_id = m.thread_id
             AND r.user_id = m.manager_user_id
             AND ($4::boolean = TRUE OR r.from_bot = FALSE)
            WHERE m.manager_user_id IS NOT NULL
            GROUP BY m.board_id, m.manager_user_id
        ),
        mgr_named AS (
            -- 带上名字
            SELECT
                mc.board_id,
                mc.manager_user_id,
                mc.cnt,
                u.first_name,
                u.last_name
            FROM mgr_cnt mc
            LEFT JOIN "user" u
              ON u.user_id = mc.manager_user_id
        )
        SELECT
            b.board_id,
            b.board_title,
            b.thread_id,
            COALESCE(msg.msg_count, 0) AS msg_count,
            b.funds,
            COALESCE(
                jsonb_agg(
                    jsonb_build_object(
                        'manager_user_id', mn.manager_user_id,
                        'first_name', COALESCE(mn.first_name, ''),
                        'last_name',  COALESCE(mn.last_name,  ''),
                        'manager_msg_count', mn.cnt
                    )
                    ORDER BY mn.manager_user_id
                ) FILTER (WHERE mn.manager_user_id IS NOT NULL),
                '[]'::jsonb
            ) AS managers
        FROM b
        LEFT JOIN msg
          ON msg.thread_id = b.thread_id
        LEFT JOIN mgr_named mn
          ON mn.board_id = b.board_id
        GROUP BY
            b.board_id, b.board_title, b.thread_id, msg.msg_count, b.funds
        ORDER BY
            msg.msg_count DESC NULLS LAST,
            b.thread_id ASC;
        """

        async with cls.pool.acquire() as conn:
            rows = await conn.fetch(
                sql,
                int(tg_chat_id),
                stat_date_from,
                stat_date_to,
                bool(include_bots),
            )

        out: list[dict[str, Any]] = []
        for r in rows:
            d = dict(r)
            if isinstance(d.get("managers"), str):
                import json
                d["managers"] = json.loads(d["managers"])
            out.append(d)

        return out






    @classmethod
    async def fetch_due_tasks_locked(cls, now_epoch: int, limit: int = 20) -> list[dict]:
        """
        到期条件：task_time IS NULL 或 now > task_time + task_interval
        并发安全：FOR UPDATE SKIP LOCKED
        """
        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化")

        sql = """
        SELECT task_id, task_title, task_value, task_time, task_interval, task_exec
        FROM task_rec
        WHERE (task_time IS NULL)
           OR ($1 > task_time + task_interval)
        ORDER BY COALESCE(task_time, 0) ASC
        FOR UPDATE SKIP LOCKED
        LIMIT $2;
        """
        async with cls.pool.acquire() as conn:
            async with conn.transaction():
                rows = await conn.fetch(sql, int(now_epoch), int(limit))
                return [dict(r) for r in rows]

    @classmethod
    async def touch_task_time(cls, task_id: int, now_epoch: int) -> None:
        if cls.pool is None:
            raise RuntimeError("PGStatsDB.pool 尚未初始化")
        sql = "UPDATE task_rec SET task_time = $2 WHERE task_id = $1;"
        async with cls.pool.acquire() as conn:
            await conn.execute(sql, int(task_id), int(now_epoch))


''''''