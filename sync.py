import asyncio
import jieba
from lz_pgsql import PGPool

# sync_mysql_pool.py
import os
import aiomysql
from typing import Optional, Tuple, Any, Dict, List, Set
from lexicon_manager import LexiconManager


class MySQLPool:
    """
    æœ€å°åŒ– MySQL è¿æ¥æ± ï¼šä»…æœåŠ¡ sync()/check_file_record() è¿™æ¡é“¾è·¯
    - init_pool()
    - ensure_pool()
    - get_conn_cursor()
    - release()
    - close()
    """

    _pool: Optional[aiomysql.Pool] = None

    @classmethod
    async def init_pool(cls) -> None:
        if cls._pool is not None:
            return

        from lz_config import MYSQL_HOST, MYSQL_USER, MYSQL_PASSWORD, MYSQL_DB, MYSQL_DB_PORT

        host = os.getenv("MYSQL_HOST", "127.0.0.1")
        port = int(os.getenv("MYSQL_PORT", "3306"))
        user = os.getenv("MYSQL_USER", "root")
        password = os.getenv("MYSQL_PASSWORD", "")
        db = os.getenv("MYSQL_DB", "telebot")
        minsize = int(os.getenv("MYSQL_POOL_MIN", "1"))
        maxsize = int(os.getenv("MYSQL_POOL_MAX", "10"))
        charset = os.getenv("MYSQL_CHARSET", "utf8mb4")

       

        cls._pool = await aiomysql.create_pool(
            host=MYSQL_HOST,
            user=MYSQL_USER,
            password=MYSQL_PASSWORD,
            db=MYSQL_DB,
            port=MYSQL_DB_PORT,
            charset="utf8mb4",
            autocommit=True,
            minsize=2,
            maxsize=32,
            pool_recycle=1800,
            connect_timeout=10,
        )

        print("âœ… [SyncMySQLPool] MySQL è¿æ¥æ± åˆå§‹åŒ–å®Œæˆ", flush=True)

    @classmethod
    async def ensure_pool(cls) -> aiomysql.Pool:
        if cls._pool is None:
            raise RuntimeError("SyncMySQLPool not initialized. Call init_pool() first.")
        return cls._pool

    @classmethod
    async def get_conn_cursor(cls) -> Tuple[aiomysql.Connection, aiomysql.Cursor]:
        """
        è¿”å› (conn, cur)ï¼›cur é»˜è®¤ DictCursorï¼Œç¬¦åˆä½ ç›®å‰ä»£ç ä½¿ç”¨ r['id'] è¿™ç§è®¿é—®æ–¹å¼
        """
        pool = await cls.ensure_pool()
        conn = await pool.acquire()
        try:
            cur = await conn.cursor(aiomysql.DictCursor)
        except Exception:
            pool.release(conn)
            raise
        return conn, cur

    @classmethod
    async def release(cls, conn: Any, cur: Any) -> None:
        """
        ä¸ä½ å½“å‰ä»£ç é£æ ¼ä¸€è‡´ï¼šæ— è®ºæˆåŠŸå¤±è´¥ï¼Œéƒ½å¯ä»¥å®‰å…¨ release
        """
        try:
            if cur is not None:
                await cur.close()
        except Exception:
            pass

        try:
            if cls._pool is not None and conn is not None:
                cls._pool.release(conn)
        except Exception:
            pass

    @classmethod
    async def close(cls) -> None:
        if cls._pool is None:
            return
        cls._pool.close()
        try:
            await cls._pool.wait_closed()
        except Exception:
            pass
        cls._pool = None
        print("ğŸ›‘ [SyncMySQLPool] MySQL è¿æ¥æ± å·²å…³é—­", flush=True)




async def sync():

    summary = await apply_thumb_from_bid_thumbnail_t5_batched(
        batch_size=500,
        sleep_seconds=0.05,
    )

    # summary = await dedupe_bid_thumbnail_t_update4_to5_batched(
    #     batch_groups=500,
    #     sleep_seconds=0.05,
    # )
    # await sync_bid_thumbnail_t_update_batched()
    # await sync_product_mysql_to_postgres_no_json_fix()
    # await MySQLPool.init_pool()
    # await diff_bodyexam_files()

    # # 1. åŒæ­¥ / ä¿®å¤ file_record
    # while False:
    #     summary = await check_file_record(limit=100)
    #     if summary.get("checked", 0) == 0:
    #         break

    # await MySQLPool.init_pool()
    # while True:
    #     r = await check_and_fix_file_tag_avalible(limit=2000)
    #     print(r, flush=True)
    #     if r["checked"] == 0:
    #         break



    # 2. å¦‚éœ€å¯ç”¨ä»¥ä¸‹ä¿®å¤é€»è¾‘ï¼Œå–æ¶ˆæ³¨é‡Šå³å¯
    #
    # while True:
    #     summary = await check_and_fix_sora_valid_state(limit=1000)
    #     if summary.get("checked", 0) == 0:
    #         break
    #
    # while True:
    #     summary = await check_and_fix_sora_valid_state2(limit=1000)
    #     if summary.get("checked", 0) == 0:
    #         break



'''
åŒæ­¥ product è¡¨
'''
async def sync_product_mysql_to_postgres_no_json_fix(
    batch_size: int = 2000,
) -> Dict[str, int]:
    """
    å…¨é‡åŒæ­¥ MySQL.product -> PostgreSQL.public.productï¼ˆPG ç›®å‰ä¸ºç©ºä¹Ÿå¯ç”¨ï¼‰
    - PG product.id æ˜¾å¼å†™å…¥ MySQL.idï¼ˆä¸èµ° nextvalï¼‰
    - purchase_condition ä¸åšä»»ä½•æ¸…æ´—/å®¹é”™ï¼šåŸæ ·å†™å…¥ï¼Œå¹¶åœ¨ PG ç«¯å¼ºåˆ¶ ::jsonb
      => åªè¦é‡åˆ°ä¸åˆæ³• JSONï¼Œä¼šç›´æ¥æŠ¥é”™ä¸­æ–­ï¼ˆç¬¦åˆâ€œä¸å¤„ç† JSON ä¸åˆæ³•â€çš„è¦æ±‚ï¼‰
    - åŒæ­¥å®Œæˆåä¿®æ­£ product_id_seqï¼Œé¿å…åç»­ nextval æ’å·
    """
    await MySQLPool.init_pool()
    await PGPool.init_pool()
    await MySQLPool.ensure_pool()
    await PGPool.ensure_pool()

    fetched = 0
    inserted_or_updated = 0
    last_id = 0

    while True:
        conn, cur = await MySQLPool.get_conn_cursor()
        try:
            await cur.execute(
                """
                SELECT
                    id,
                    name,
                    content,
                    guild_id,
                    price,
                    content_id,
                    file_type,
                    owner_user_id,
                    anonymous_mode,
                    view_times,
                    purchase_times,
                    like_times,
                    dislike_times,
                    hot_score,
                    bid_status,
                    review_status,
                    purchase_condition,
                    created_at,
                    updated_at
                FROM product
                WHERE id > %s
                ORDER BY id ASC
                LIMIT %s
                """,
                (int(last_id), int(batch_size)),
            )
            rows = await cur.fetchall()
        finally:
            await MySQLPool.release(conn, cur)

        if not rows:
            break

        fetched += len(rows)
        last_id = int(rows[-1]["id"])

        payload: List[Tuple[Any, ...]] = []
        for r in rows:
            payload.append((
                int(r["id"]),
                r.get("name"),
                r.get("content"),
                r.get("guild_id"),
                int(r.get("price") or 0),
                int(r["content_id"]),
                r.get("file_type"),
                r.get("owner_user_id"),
                int(r.get("anonymous_mode") or 1),
                int(r.get("view_times") or 0),
                int(r.get("purchase_times") or 0),
                int(r.get("like_times") or 0),
                int(r.get("dislike_times") or 0),
                int(r.get("hot_score") or 0),
                int(r.get("bid_status") or 0),
                int(r.get("review_status") or 0),
                r.get("purchase_condition"),  # åŸæ ·ï¼šstr/None
                r.get("created_at"),
                r.get("updated_at"),
            ))

        pg_conn = await PGPool.acquire()
        try:
            sql = """
                INSERT INTO public.product (
                    id,
                    name,
                    content,
                    guild_id,
                    price,
                    content_id,
                    file_type,
                    owner_user_id,
                    anonymous_mode,
                    view_times,
                    purchase_times,
                    like_times,
                    dislike_times,
                    hot_score,
                    bid_status,
                    review_status,
                    purchase_condition,
                    created_at,
                    updated_at
                )
                VALUES (
                    $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,
                    $11,$12,$13,$14,$15,$16,
                    $17,
                    $18,$19
                )
                ON CONFLICT (content_id) DO UPDATE SET
                    id = EXCLUDED.id,
                    name = EXCLUDED.name,
                    content = EXCLUDED.content,
                    guild_id = EXCLUDED.guild_id,
                    price = EXCLUDED.price,
                    file_type = EXCLUDED.file_type,
                    owner_user_id = EXCLUDED.owner_user_id,
                    anonymous_mode = EXCLUDED.anonymous_mode,
                    view_times = EXCLUDED.view_times,
                    purchase_times = EXCLUDED.purchase_times,
                    like_times = EXCLUDED.like_times,
                    dislike_times = EXCLUDED.dislike_times,
                    hot_score = EXCLUDED.hot_score,
                    bid_status = EXCLUDED.bid_status,
                    review_status = EXCLUDED.review_status,
                    purchase_condition = EXCLUDED.purchase_condition,
                    created_at = COALESCE(EXCLUDED.created_at, public.product.created_at),
                    updated_at = COALESCE(EXCLUDED.updated_at, public.product.updated_at)
            """
            async with pg_conn.transaction():
                await pg_conn.executemany(sql, payload)
                inserted_or_updated += len(payload)
        finally:
            await PGPool.release(pg_conn)

        print(f"âœ… [product sync] batch done, last_id={last_id}, rows={len(rows)}", flush=True)

    # ä¿®æ­£ sequence
    pg_conn = await PGPool.acquire()
    try:
        async with pg_conn.transaction():
            await pg_conn.execute(
                """
                SELECT setval(
                    'product_id_seq',
                    GREATEST((SELECT COALESCE(MAX(id), 0) FROM public.product), 1),
                    true
                )
                """
            )
    finally:
        await PGPool.release(pg_conn)

    summary = {"fetched": fetched, "inserted_or_updated": inserted_or_updated}
    print(f"ğŸ¯ [product sync] DONE: {summary}", flush=True)
    return summary

''''
'''



def _escape_ts_lexeme(s: str) -> str:
    # ç®€å•è½¬ä¹‰ï¼Œé¿å… to_tsquery ç‰¹æ®Šå­—ç¬¦å½±å“ï¼›å¿…è¦æ—¶å†æ‰©å……
    return s.replace("'", "''").replace("&", " ").replace("|", " ").replace("!", " ").replace(":", " ").strip()



  # ğŸ”¹ æ–°å¢ï¼šæ”¯æŒåŒä¹‰è¯ OR ç»„çš„ç‰ˆæœ¬
def _build_tsqueries_from_token_groups(token_groups: list[list[str]]) -> tuple[str, str]:
    """
    token_groups ç»“æ„ç¤ºä¾‹ï¼š
    [
        ["é¼ æ ‡", "æ»‘é¼ "],
        ["ä¹°"]
    ]

    ç”Ÿæˆï¼š
    phrase_q: "(é¼ æ ‡ | æ»‘é¼ ) <-> ä¹°"
    and_q:    "(é¼ æ ‡ | æ»‘é¼ ) & ä¹°"
    """
    phrase_parts: list[str] = []
    and_parts: list[str] = []

    for group in token_groups:
        # æ¸…æ´— + å»ç©º + å»é‡
        cleaned = {
            _escape_ts_lexeme(t)
            for t in group
            if t and t.strip()
        }
        if not cleaned:
            continue

        if len(cleaned) == 1:
            term = next(iter(cleaned))
        else:
            # åŒä¹‰è¯ OR
            term = "(" + " | ".join(sorted(cleaned)) + ")"

        phrase_parts.append(term)
        and_parts.append(term)

    if not and_parts:
        return "", ""

    phrase_q = " <-> ".join(phrase_parts) if phrase_parts else ""
    and_q = " & ".join(and_parts)
    return phrase_q, and_q

async def search(keyword_str):
   
    # 2) åˆ†è¯
    jieba.load_userdict("jieba_userdict.txt")

    tokens = list(jieba.cut(keyword_str))
    print("Tokens after jieba cut:", tokens)

    # 3) åœç”¨è¯è¿‡æ»¤ï¼ˆç”¨ search_stopwords.txtï¼Œä¸“æœ‰åè¯ä¼šä¿ç•™ï¼‰
    tokens = LexiconManager.filter_stop_words(tokens)
    print("Tokens after stop-word filter:", tokens)

    # 4) åŒä¹‰è¯å åŠ ï¼šæ¯ä¸ª token -> [æœ¬è¯ + å…¨éƒ¨åŒä¹‰è¯]
    token_groups = LexiconManager.expand_tokens(tokens)
    print("Token groups after synonym expand:", token_groups)

    # 5) ç”Ÿæˆ tsqueryï¼šç”¨ OR ç»„æ„æˆ phrase_q / and_q
    phrase_q, and_q = _build_tsqueries_from_token_groups(token_groups)
    if not and_q:
        return []

    # ä¸‹é¢çš„ limit / where_parts / params / SQL æ„é€ éƒ½ç»´æŒåŸæ ·ï¼Œä¸åŠ¨
    # 4) ä¿æŠ¤ limit
   

    where_parts = []
    params = []

    # ===== å…ˆç»Ÿä¸€å†³å®šå‚æ•°é¡ºåº =====
    current_idx = 1
    phrase_idx = None
    and_idx = None

    cond = []

    if phrase_q:
        phrase_idx = current_idx
        params.append(phrase_q)
        cond.append(f"content_seg_tsv @@ to_tsquery('simple', ${phrase_idx})")
        current_idx += 1

    # and_q ä¸€å®šå­˜åœ¨
    and_idx = current_idx
    params.append(and_q)
    cond.append(f"content_seg_tsv @@ to_tsquery('simple', ${and_idx})")
    current_idx += 1

    where_parts.append("(" + " OR ".join(cond) + ")")




    if phrase_idx is not None:
        rank_expr = f"""
            GREATEST(
                COALESCE(ts_rank_cd(content_seg_tsv, to_tsquery('simple', ${phrase_idx})), 0) * 1.5,
                ts_rank_cd(content_seg_tsv, to_tsquery('simple', ${and_idx}))
            )
        """
    else:
        rank_expr = f"ts_rank_cd(content_seg_tsv, to_tsquery('simple', ${and_idx}))"

    sql = f"""
        SELECT
            source_id,
            {rank_expr} AS rank
        FROM sora_content
        WHERE {' AND '.join(where_parts)} AND valid_state >= 8
        ORDER BY rank DESC, id DESC
        
    """

    # print("SQL:", sql, "PARAMS:", params, flush=True)

    pg_conn = await PGPool.acquire()
    try:

        async with pg_conn.transaction():
            rows = await pg_conn.fetch(sql, *params)
            return rows
        # asyncpg: "UPDATE <n>"
       
    finally:
        await PGPool.release(pg_conn)

    
async def get_file_tag_bodyexam():
    await MySQLPool.ensure_pool()
    conn, cur = await MySQLPool.get_conn_cursor()
    try:
        await cur.execute("""
            SELECT file_unique_id
            FROM file_tag
            WHERE tag = 'bodyexam'
              AND avalible = 1
        """)
        rows = await cur.fetchall()
        return rows
    finally:
        await MySQLPool.release(conn, cur)
   
async def diff_bodyexam_files():
    # A rowsï¼šæ¥è‡ª search
    a_rows = await search("èº«ä½“æ£€æŸ¥")
    a_ids = {r["source_id"] for r in a_rows if r.get("source_id")}

    print(f"[A] search å‘½ä¸­æ•°é‡: {len(a_ids)}")

    # B rowsï¼šæ¥è‡ª file_tag
    b_rows = await get_file_tag_bodyexam()
    b_ids = {r["file_unique_id"] for r in b_rows if r.get("file_unique_id")}

    print(f"[B] file_tag(bodyexam, avalible=1) æ•°é‡: {len(b_ids)}")

    # C rowsï¼šB - A
    c_ids = b_ids - a_ids

    print(f"[C] éœ€è¦å¤„ç†çš„ file_unique_id æ•°é‡: {len(c_ids)}")
    if not c_ids:
        print("âœ… æ— éœ€æ›´æ–° content_seg")
        return set()

    # ğŸ”¹ æ ¸å¿ƒæ–°å¢é€»è¾‘
    updated = await append_bodyexam_to_content_seg(c_ids)
    print(f"ğŸ©º å·²æ›´æ–° content_segï¼ˆèº«ä½“æ£€æŸ¥ï¼‰è¡Œæ•°: {updated}")

    return c_ids


from typing import Set

async def append_bodyexam_to_content_seg(file_unique_ids: Set[str]) -> int:
    """
    ç»™ sora_content.content_seg è¿½åŠ  'èº«ä½“æ£€æŸ¥'
    - ä¸é‡å¤è¿½åŠ 
    - è‡ªåŠ¨è§¦å‘ content_seg_tsv é‡ç®—
    """
    if not file_unique_ids:
        return 0

    await PGPool.ensure_pool()
    pg_conn = await PGPool.acquire()
    try:
        sql = """
            UPDATE sora_content
            SET content_seg =
                CASE
                    WHEN content_seg IS NULL OR content_seg = ''
                        THEN 'èº«ä½“æ£€æŸ¥'
                    WHEN content_seg LIKE '%èº«ä½“æ£€æŸ¥%'
                        THEN content_seg
                    ELSE content_seg || ' èº«ä½“æ£€æŸ¥'
                END
            WHERE source_id = ANY($1::text[])
        """
        async with pg_conn.transaction():
            result = await pg_conn.execute(sql, list(file_unique_ids))

        # asyncpg è¿”å›æ ¼å¼ï¼š"UPDATE <n>"
        return int(result.split()[-1])
    finally:
        await PGPool.release(pg_conn)



async def check_and_fix_file_tag_avalible(limit: int = 2000) -> Dict[str, Any]:
    """
    ä¿®å¤ file_tag.avalibleï¼š
    - file_tag.avalible=0 ä¸”åœ¨ file_extension å­˜åœ¨ç›¸åŒ file_unique_id -> avalible=1
    - file_tag.avalible=0 ä¸”åœ¨ file_extension ä¸å­˜åœ¨ -> avalible=2

    ä»¥æ‰¹æ¬¡æ›´æ–°æ–¹å¼å‡å°‘é•¿äº‹åŠ¡ä¸é”ç«äº‰ï¼›ä¸ä¼šé”è¡¨ï¼Œåªä¼šé”æœ¬æ‰¹æ¬¡å‘½ä¸­çš„è¡Œã€‚
    """
   
    await MySQLPool.ensure_pool()

    conn, cur = await MySQLPool.get_conn_cursor()
    try:
        await conn.begin()

        # 1) å­˜åœ¨äº file_extensionï¼šç½® 1
        sql_exists = """
            UPDATE file_tag ft
            INNER JOIN file_extension fe
                ON fe.file_unique_id = ft.file_unique_id
            SET ft.avalible = 1
            WHERE ft.avalible = 0
            ORDER BY ft.id
            LIMIT %s
        """
        await cur.execute(sql_exists, (int(limit),))
        updated_to_1 = cur.rowcount or 0

        # 2) ä¸å­˜åœ¨äº file_extensionï¼šç½® 2
        # åªå¤„ç†ä»ä¸º avalible=0 çš„ï¼ˆé¿å…è¦†ç›–ä¸Šä¸€æ­¥å·²ç½® 1 çš„ï¼‰
        sql_missing = """
            UPDATE file_tag ft
            LEFT JOIN file_extension fe
                ON fe.file_unique_id = ft.file_unique_id
            SET ft.avalible = 2
            WHERE ft.avalible = 0
                AND fe.file_unique_id IS NULL
            ORDER BY ft.id
            LIMIT %s
        """
        await cur.execute(sql_missing, (int(limit),))
        updated_to_2 = cur.rowcount or 0

        await conn.commit()

        return {
            "checked": updated_to_1 + updated_to_2,  # æœ¬æ‰¹æ¬¡å®é™…æ›´æ–°è¡Œæ•°
            "updated_to_1": updated_to_1,
            "updated_to_2": updated_to_2,
        }

    except Exception as e:
        try:
            await conn.rollback()
        except Exception:
            pass
        raise RuntimeError(f"[check_and_fix_file_tag_avalible] failed: {e}") from e
    finally:
        await MySQLPool.release(conn, cur)



async def check_file_record(limit:int = 100):
    '''
    ä» Mysql table file_records3 ä¸­å–å‡º limit æ¡è®°å½•
    (1) ç”¨ insert/update è¯­å¥æ’å…¥åˆ° mysql çš„ table file_unique_id ä¸­ , 
    file_records3.file_unique_id å¯¹åº” file_unique_id.file_unique_id,
    file_records3.file_id å¯¹åº” file_unique_id.file_id
    file_records3.file_type å¯¹åº” file_unique_id.file_type
    file_records3.bot_id è½¬è¯‘åå¯¹åº” file_unique_id.bot (å…¶ä¸­ bot_id:7985482732 = bot:Queue9838bot, bot_id:7629569353 = bot:stcparkbot )
    (2) æ ¹æ® file_records3.file_type, åˆ†åˆ«ç»´æŠ¤è¡¨ video, photo, document, animation, å¹¶ä»¥ insert/update è¯­å¥æ’å…¥/æ›´æ–°å¯¹åº”çš„è®°å½•
    [Tabble].file_unique_id å¯¹åº”å„è¡¨çš„ file_records3.file_unique_id
    [Table].file_size å¯¹åº”å„è¡¨çš„ file_records3.file_size
    [Table].mime_type å¯¹åº”å„è¡¨çš„ file_records3.mime_type
    [Table].file_name å¯¹åº”å„è¡¨çš„ file_records3.file_name
    (3) å°† MySQL ä¸­ table sora_content ä¸­ sora_content.source_id = file_records3.file_unique_id çš„è®°å½•, valid_state æ›´æ–°ä¸º 9, stage æ›´æ–°ä¸º pending
    (4) å°† PostgreSQL ä¸­ table sora_content ä¸­ sora_content.source_id = file_records3.file_unique_id çš„è®°å½•, valid_state æ›´æ–°ä¸º 9, stage æ›´æ–°ä¸º pending
    (5) åˆ é™¤ file_records3 ä¸­å·²ç»å¤„ç†è¿‡çš„è®°å½•


    '''



    # ---------- 0) Pools ----------
    await asyncio.gather(MySQLPool.init_pool(), PGPool.init_pool())
    await MySQLPool.ensure_pool()
    await PGPool.ensure_pool()

    # ---------- 1) Fetch file_records3 ----------
    conn, cur = await MySQLPool.get_conn_cursor()
    try:
        await cur.execute(
            """
            SELECT
                id,
                file_unique_id,
                file_id,
                file_type,
                bot_id,
                man_id,
                file_size,
                mime_type,
                file_name
            FROM file_records3 
            WHERE process = 0
            LIMIT %s
            """,
            (int(limit),),
        )
        rows = await cur.fetchall()
    except Exception as e:
        print(f"âš ï¸ [check_file_record] MySQL æŸ¥è¯¢ file_records3 å‡ºé”™: {e}", flush=True)
        await MySQLPool.release(conn, cur)
        return {
            "checked": 0,
            "upsert_file_ext": 0,
            "upsert_media": 0,
            "updated_mysql": 0,
            "updated_pg": 0,
            "deleted": 0,
            "skipped_photo": 0,
        }
    finally:
        await MySQLPool.release(conn, cur)

    if not rows:
        print("[check_file_record] file_records3 æ— å¾…å¤„ç†è®°å½•ã€‚", flush=True)
        return {
            "checked": 0,
            "upsert_file_ext": 0,
            "upsert_media": 0,
            "updated_mysql": 0,
            "updated_pg": 0,
            "deleted": 0,
            "skipped_photo": 0,
        }

    checked = len(rows)

    # ---------- 2) Helpers ----------
    BOT_ID_MAP = {
        7985482732: "Queue9838bot",
        7629569353: "stcparkbot",
    }

    def bot_name_of(bot_id) -> str:
        try:
            bid = int(bot_id) if bot_id is not None else None
        except Exception:
            bid = None
        if bid is None:
            return "unknown"
        return BOT_ID_MAP.get(bid, str(bid))

    def normalize_ft(ft: str) -> str:
        ft = (ft or "").lower().strip()
        if ft in ("v", "video"):
            return "video"
        if ft in ("a", "animation"):
            return "animation"
        if ft in ("d", "document"):
            return "document"
        if ft in ("p", "photo"):
            return "photo"
        return ""

    def safe_sid50(fu: str) -> str:
        return str(fu)[:50]  # MySQL sora_content.source_id = varchar(50); PG ä¹Ÿç»Ÿä¸€ç”¨ 50

    def safe_fu100(fu: str) -> str:
        return str(fu)[:100]  # file_extension.file_unique_id = varchar(100)

    # ---------- 3) Build payloads ----------
    record_ids: list[int] = []
    source_ids_50: list[str] = []

    file_ext_payload = []  # (file_type, file_unique_id(100), file_id, bot, user_id)

    media_payload_v = []  # video: (fu, file_size, duration, width, height, file_name, mime_type, caption)
    media_payload_a = []  # animation
    media_payload_d = []  # document: (fu, file_size, file_name, mime_type, caption)
    media_payload_p = []  # photo: (fu, file_size, width, height, file_name, caption, root_unique_id)

    skipped_photo = 0

    # æ³¨æ„ï¼šfile_records3 è¿™å¼ è¡¨ç»“æ„é‡Œæ²¡æœ‰ duration/width/height/caption/root_unique_id
    # å› æ­¤ï¼š
    # - video/animation/document å¯ä»¥å†™ NULLï¼ˆå…è®¸ï¼‰
    # - photo å›  width/height NOT NULL -> ç¼ºå¤±åªèƒ½è·³è¿‡
    for r in rows:
        rid = int(r["id"])
        fu = r.get("file_unique_id")
        fid = r.get("file_id")
        if not fu or not fid:
            continue

        record_ids.append(rid)

        sid50 = safe_sid50(fu)
        source_ids_50.append(sid50)

        bot = bot_name_of(r.get("bot_id"))
        fu100 = safe_fu100(fu)

        file_ext_payload.append((
            r.get("file_type"),
            fu100,
            fid,
            bot,
            r.get("man_id"),  # æ˜ å°„åˆ° file_extension.user_id
        ))

        ft_norm = normalize_ft(r.get("file_type"))
        file_size = r.get("file_size") or 0
        mime_type = r.get("mime_type")
        file_name = r.get("file_name")

        if ft_norm == "video":
            media_payload_v.append((
                fu100,
                int(file_size),
                None,  # duration
                None,  # width
                None,  # height
                file_name,
                mime_type or "video/mp4",
                None,  # caption
            ))
        elif ft_norm == "animation":
            media_payload_a.append((
                fu100,
                int(file_size),
                None,
                None,
                None,
                file_name,
                mime_type or "video/mp4",
                None,
            ))
        elif ft_norm == "document":
            media_payload_d.append((
                fu100,
                int(file_size),
                file_name,
                mime_type,
                None,  # caption
            ))
        elif ft_norm == "photo":
            # file_records3 ç¼º width/height -> å¿…é¡»è·³è¿‡
            skipped_photo += 1
            continue

    # å»é‡ï¼ˆä¿æŒé¡ºåºï¼‰
    source_ids_50 = list(dict.fromkeys(source_ids_50))

    if not record_ids:
        return {
            "checked": checked,
            "upsert_file_ext": 0,
            "upsert_media": 0,
            "updated_mysql": 0,
            "updated_pg": 0,
            "deleted": 0,
            "skipped_photo": skipped_photo,
        }

    # ---------- 4) MySQL Transaction ----------
    upsert_file_ext = 0
    upsert_media = 0
    updated_mysql = 0
    deleted = 0

    conn, cur = await MySQLPool.get_conn_cursor()
    try:
        await conn.begin()

        # 4.1 upsert file_extensionï¼ˆUNIQUE(file_id, bot)ï¼‰
        # create_timeï¼šæ–°æ’å…¥ç”¨ NOW()ï¼›é‡å¤æ—¶ä¸å¼ºåˆ¶è¦†ç›–ï¼ˆä¿ç•™æ—§å€¼ï¼‰ï¼ŒåŒæ—¶æ›´æ–° file_type/file_unique_id/user_id
        if file_ext_payload:
            sql_ext = """
                INSERT INTO file_extension
                    (file_type, file_unique_id, file_id, bot, user_id, create_time)
                VALUES
                    (%s, %s, %s, %s, %s, NOW())
                ON DUPLICATE KEY UPDATE
                    file_type      = VALUES(file_type),
                    file_unique_id = VALUES(file_unique_id),
                    user_id        = COALESCE(VALUES(user_id), user_id)
            """
            await cur.executemany(sql_ext, file_ext_payload)
            upsert_file_ext = cur.rowcount or 0

        # 4.2 upsert video/animation/document/photoï¼ˆæŒ‰ä½  DDLï¼‰
        async def _upsert_video_like(table_name: str, payload: list) -> int:
            if not payload:
                return 0
            sql = f"""
                INSERT INTO {table_name}
                    (file_unique_id, file_size, duration, width, height, file_name, mime_type, caption, create_time, update_time)
                VALUES
                    (%s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW())
                ON DUPLICATE KEY UPDATE
                    file_size   = VALUES(file_size),
                    duration    = VALUES(duration),
                    width       = VALUES(width),
                    height      = VALUES(height),
                    file_name   = VALUES(file_name),
                    mime_type   = VALUES(mime_type),
                    caption     = VALUES(caption),
                    update_time = NOW()
            """
            await cur.executemany(sql, payload)
            return cur.rowcount or 0

        async def _upsert_document(payload: list) -> int:
            if not payload:
                return 0
            sql = """
                INSERT INTO document
                    (file_unique_id, file_size, file_name, mime_type, caption, create_time, update_time)
                VALUES
                    (%s, %s, %s, %s, %s, NOW(), NOW())
                ON DUPLICATE KEY UPDATE
                    file_size   = VALUES(file_size),
                    file_name   = VALUES(file_name),
                    mime_type   = VALUES(mime_type),
                    caption     = VALUES(caption),
                    update_time = NOW()
            """
            await cur.executemany(sql, payload)
            return cur.rowcount or 0

        async def _upsert_photo(payload: list) -> int:
            # åŸºäºä½ å½“å‰ file_records3 ç¼º width/heightï¼Œè¿™é‡Œé€šå¸¸ä¸ä¼šè¢«è°ƒç”¨
            if not payload:
                return 0
            sql = """
                INSERT INTO photo
                    (file_unique_id, file_size, width, height, file_name, caption, root_unique_id, create_time, update_time)
                VALUES
                    (%s, %s, %s, %s, %s, %s, %s, NOW(), NOW())
                ON DUPLICATE KEY UPDATE
                    file_size   = VALUES(file_size),
                    width       = VALUES(width),
                    height      = VALUES(height),
                    file_name   = VALUES(file_name),
                    caption     = VALUES(caption),
                    root_unique_id = VALUES(root_unique_id),
                    update_time = NOW()
            """
            await cur.executemany(sql, payload)
            return cur.rowcount or 0

        upsert_media += await _upsert_video_like("video", media_payload_v)
        upsert_media += await _upsert_video_like("animation", media_payload_a)
        upsert_media += await _upsert_document(media_payload_d)
        upsert_media += await _upsert_photo(media_payload_p)

        # 4.3 UPDATE MySQL sora_contentï¼ˆåªæ›´æ–°å·²å­˜åœ¨ï¼›ä¸æ’å…¥æ–°è¡Œï¼‰
        # åˆ†æ‰¹é¿å… IN è¿‡é•¿
        BATCH = 500
        if source_ids_50:
            for i in range(0, len(source_ids_50), BATCH):
                batch_sids = source_ids_50[i:i + BATCH]
                placeholders = ",".join(["%s"] * len(batch_sids))
                sql_sc = f"""
                    UPDATE sora_content
                    SET valid_state = 9,
                        stage = 'pending'
                    WHERE source_id IN ({placeholders})
                """
                await cur.execute(sql_sc, tuple(batch_sids))
                updated_mysql += cur.rowcount or 0

        # 4.4 è½¯åˆ é™¤æœ¬æ‰¹å·²å¤„ç† file_records3
        if record_ids:
            for i in range(0, len(record_ids), BATCH):
                batch_ids = record_ids[i:i + BATCH]
                placeholders = ",".join(["%s"] * len(batch_ids))
                sql_del = f"UPDATE file_records3 SET process = 1 WHERE id IN ({placeholders})"
                await cur.execute(sql_del, tuple(batch_ids))


                sql_del = f"UPDATE file_records3 SET process = 1 WHERE id IN ({placeholders})"
                await cur.execute(sql_del, tuple(batch_ids))

                deleted += cur.rowcount or 0

        await conn.commit()

    except Exception as e:
        try:
            await conn.rollback()
        except Exception:
            pass
        print(f"âŒ [check_file_record] MySQL äº‹åŠ¡å¤±è´¥å¹¶å›æ»š: {e}", flush=True)
        # MySQL å¤±è´¥åˆ™ PG ä¸åšæ›´æ–°ï¼ˆé¿å…ä¸¤è¾¹çŠ¶æ€ä¸ä¸€è‡´ï¼‰
        return {
            "checked": checked,
            "upsert_file_ext": upsert_file_ext,
            "upsert_media": upsert_media,
            "updated_mysql": updated_mysql,
            "updated_pg": 0,
            "deleted": 0,
            "skipped_photo": skipped_photo,
        }
    finally:
        await MySQLPool.release(conn, cur)

    # ---------- 5) PostgreSQL UPDATE (B1 only) ----------
    updated_pg = 0
    try:
        if source_ids_50:
            pg_conn = await PGPool.acquire()
            try:
                sql_pg = """
                    UPDATE public.sora_content
                    SET valid_state = 9,
                        stage = 'pending'
                    WHERE source_id = ANY($1::text[])
                """
                async with pg_conn.transaction():
                    result = await pg_conn.execute(sql_pg, source_ids_50)

                # asyncpg: "UPDATE <n>"
                try:
                    updated_pg = int(str(result).split()[-1])
                except Exception:
                    updated_pg = 0
            finally:
                await PGPool.release(pg_conn)

    except Exception as e:
        print(f"âš ï¸ [check_file_record] PostgreSQL UPDATE sora_content å‡ºé”™: {e}", flush=True)

    summary = {
        "checked": checked,
        "upsert_file_ext": upsert_file_ext,
        "upsert_media": upsert_media,
        "updated_mysql": updated_mysql,
        "updated_pg": updated_pg,
        "deleted": deleted,
        "skipped_photo": skipped_photo,
    }
    print(f"[check_file_record] Done: {summary}", flush=True)
    return summary



async def sync_bid_thumbnail_t_update_batched(
    batch_size: int = 2000,
    sleep_seconds: float = 0.0,
    max_rounds: Optional[int] = None,
    ensure_index: bool = False,
) -> Dict[str, Any]:
    """
    åˆ†æ‰¹ä¿®å¤ bid_thumbnail.t_updateï¼š
    - t_update=2 ä¸” file_unique_id å­˜åœ¨äº file_extension -> ç½® 3
    - t_update=2 ä¸”ä¸å­˜åœ¨ -> ç½® 0

    ç‰¹æ€§ï¼š
    - åˆ†æ‰¹ï¼ˆLIMIT batch_sizeï¼‰ï¼Œé™ä½ MyISAM è¡¨é”å½±å“
    - æ¯æ‰¹æ‰“å°è¿›åº¦
    - Ctrl+C å¯ä¸­æ–­ï¼šä¼šåœ¨æ‰¹æ¬¡è¾¹ç•Œå®‰å…¨é€€å‡ºï¼ˆå·²æäº¤çš„æ‰¹æ¬¡ä¸å›æ»šï¼‰

    å‚æ•°ï¼š
    - batch_size: æ¯æ‰¹æ›´æ–°è¡Œæ•°ä¸Šé™ï¼ˆå»ºè®® 500~2000ï¼‰
    - sleep_seconds: æ¯æ‰¹ä¹‹é—´ sleepï¼ˆå¯ç”¨æ¥è¿›ä¸€æ­¥é™ä½å¯¹çº¿ä¸Šå½±å“ï¼‰
    - max_rounds: æœ€å¤šè·‘å¤šå°‘è½®ï¼ˆNone è¡¨ç¤ºè·‘åˆ°æ²¡æœ‰å¯æ›´æ–°ä¸ºæ­¢ï¼‰
    - ensure_index: æ˜¯å¦å°è¯•åˆ›å»º idx_bid_thumb_tupdate_uid(t_update, file_unique_id) ç´¢å¼•
                    æ³¨æ„ï¼šMyISAM åˆ›å»ºç´¢å¼•ä¹Ÿä¼šé”è¡¨ï¼Œç”Ÿäº§ç¯å¢ƒè°¨æ…å¼€å¯

    è¿”å›ï¼š
    - ç»Ÿè®¡ä¿¡æ¯ dict
    """
    await MySQLPool.init_pool()
    await MySQLPool.ensure_pool()

    total_to_3 = 0
    total_to_0 = 0
    rounds = 0

    # å¯é€‰ï¼šåˆ›å»ºç´¢å¼•ï¼ˆå»ºè®®ä½ æ‰‹åŠ¨åœ¨ä½å³°åšï¼›è¿™é‡Œæä¾›å¼€å…³ï¼‰
    if ensure_index:
        conn, cur = await MySQLPool.get_conn_cursor()
        try:
            # MySQL 8+ å¯ç”¨ IF NOT EXISTSï¼›è‹¥ä½ ä¸æ˜¯ MySQL 8ï¼Œä¸‹é¢ä¼šæŠ¥é”™
            # ä¸ºå…¼å®¹æ€§ï¼Œæ”¹ç”¨ SHOW INDEX åˆ¤æ–­å†å»º
            await cur.execute("SHOW INDEX FROM bid_thumbnail WHERE Key_name = 'idx_bid_thumb_tupdate_uid'")
            exists = await cur.fetchone()
            if not exists:
                print("ğŸ”§ Creating index idx_bid_thumb_tupdate_uid ...", flush=True)
                await cur.execute(
                    "ALTER TABLE bid_thumbnail ADD INDEX idx_bid_thumb_tupdate_uid (t_update, file_unique_id)"
                )
                print("âœ… Index created.", flush=True)
            else:
                print("â„¹ï¸ Index already exists: idx_bid_thumb_tupdate_uid", flush=True)
        finally:
            await MySQLPool.release(conn, cur)

    print(
        f"ğŸš€ [bid_thumbnail] start batched sync: batch_size={batch_size}, sleep={sleep_seconds}, max_rounds={max_rounds}",
        flush=True,
    )

    try:
        while True:
            rounds += 1
            if max_rounds is not None and rounds > int(max_rounds):
                print(f"ğŸ›‘ Reached max_rounds={max_rounds}. Stop.", flush=True)
                break

            # ========== Batch 1: EXISTS -> 3 ==========
            conn, cur = await MySQLPool.get_conn_cursor()
            try:
                await conn.begin()
                sql_exists = f"""
                    UPDATE bid_thumbnail bt
                    INNER JOIN file_extension fe
                        ON fe.file_unique_id = bt.thumb_file_unique_id
                    SET bt.t_update = 4
                    WHERE bt.t_update = 3
                    ORDER BY bt.bid_thumbnail_id
                    LIMIT {int(batch_size)}
                """
                await cur.execute(sql_exists)
                updated_to_3 = cur.rowcount or 0
                await conn.commit()
            except Exception:
                try:
                    await conn.rollback()
                except Exception:
                    pass
                raise
            finally:
                await MySQLPool.release(conn, cur)

            total_to_3 += updated_to_3

            # ========== Batch 2: MISSING -> 0 ==========
            conn, cur = await MySQLPool.get_conn_cursor()
            try:
                await conn.begin()
                sql_missing = f"""
                    UPDATE bid_thumbnail bt
                    LEFT JOIN file_extension fe
                        ON fe.file_unique_id = bt.thumb_file_unique_id
                    SET bt.t_update = 0
                    WHERE bt.t_update = 3
                      AND fe.file_unique_id IS NULL
                    ORDER BY bt.bid_thumbnail_id
                    LIMIT {int(batch_size)}
                """
                await cur.execute(sql_missing)
                updated_to_0 = cur.rowcount or 0
                await conn.commit()
            except Exception:
                try:
                    await conn.rollback()
                except Exception:
                    pass
                raise
            finally:
                await MySQLPool.release(conn, cur)

            total_to_0 += updated_to_0

            batch_total = updated_to_3 + updated_to_0
            print(
                f"âœ… [bid_thumbnail] round={rounds} "
                f"updated_to_3={updated_to_3} updated_to_0={updated_to_0} "
                f"round_total={batch_total} "
                f"grand_total={total_to_3 + total_to_0}",
                flush=True,
            )

            # è¿™ä¸€è½®ä¸¤æ­¥éƒ½æ²¡æœ‰æ›´æ–°ï¼šç»“æŸ
            if batch_total == 0:
                print("ğŸ¯ [bid_thumbnail] no more rows to update. Done.", flush=True)
                break

            if sleep_seconds and sleep_seconds > 0:
                await asyncio.sleep(float(sleep_seconds))

    except KeyboardInterrupt:
        # å¯ä¸­æ–­ï¼šä¸ä¼šå›æ»šå·²æäº¤æ‰¹æ¬¡ï¼Œåªæ˜¯åœæ­¢åç»­æ‰¹æ¬¡
        print(
            f"â›” [bid_thumbnail] interrupted by user. "
            f"rounds={rounds} total_to_3={total_to_3} total_to_0={total_to_0}",
            flush=True,
        )

    result = {
        "rounds": rounds,
        "updated_to_3": total_to_3,
        "updated_to_0": total_to_0,
        "total": total_to_3 + total_to_0,
        "batch_size": int(batch_size),
        "sleep_seconds": float(sleep_seconds),
        "max_rounds": None if max_rounds is None else int(max_rounds),
    }
    print(f"ğŸ“Œ [bid_thumbnail] summary: {result}", flush=True)
    return result



async def dedupe_bid_thumbnail_t_update4_to5_batched(
    batch_groups: int = 1000,
    sleep_seconds: float = 0.0,
    max_rounds: Optional[int] = None,
) -> Dict[str, Any]:
    """
    å¤„ç† bid_thumbnail.t_update=4 çš„å»é‡ä¸èƒœå‡ºæ ‡è®°ï¼š
    - æŒ‰ file_unique_id åˆ†ç»„
    - æ¯ç»„æŒ‘ winnerï¼šconfirm_status æœ€å¤§ï¼›è‹¥åŒåˆ†åˆ™ bid_thumbnail_id æœ€å¤§
    - winner -> t_update=5ï¼›åŒç»„å…¶ä»–ä»ä¸º 4 çš„ -> t_update=0

    ç‰¹æ€§ï¼š
    - åˆ†æ‰¹ä»¥â€œfile_unique_id åˆ†ç»„â€ä¸ºå•ä½å¤„ç†ï¼Œé¿å…ä¸€æ¬¡æ€§é”è¡¨è¿‡ä¹…ï¼ˆMyISAM è¡¨é”æ›´æ•æ„Ÿï¼‰
    - æ¯æ‰¹æ‰“å°è¿›åº¦
    - Ctrl+C å¯ä¸­æ–­ï¼šå·²æäº¤çš„æ‰¹æ¬¡ä¸å›æ»šï¼Œåªåœæ­¢åç»­æ‰¹æ¬¡
    """

    await MySQLPool.init_pool()
    await MySQLPool.ensure_pool()

    rounds = 0
    total_groups = 0
    total_winners_set_5 = 0
    total_losers_set_0 = 0

    last_uid = ""  # ç”¨äºåˆ†é¡µï¼šfile_unique_id > last_uidï¼ˆæŒ‰å­—å…¸åºï¼‰
    print(
        f"ğŸš€ [bid_thumbnail] start t_update=4 dedupe: batch_groups={batch_groups}, sleep={sleep_seconds}, max_rounds={max_rounds}",
        flush=True,
    )

    try:
        while True:
            rounds += 1
            if max_rounds is not None and rounds > int(max_rounds):
                print(f"ğŸ›‘ Reached max_rounds={max_rounds}. Stop.", flush=True)
                break

            # 1) å–ä¸€æ‰¹ file_unique_idï¼ˆä»…é™ t_update=4ï¼‰
            conn, cur = await MySQLPool.get_conn_cursor()
            try:
                await cur.execute(
                    """
                    SELECT file_unique_id
                    FROM bid_thumbnail
                    WHERE t_update = 4
                      AND file_unique_id > %s
                    GROUP BY file_unique_id
                    ORDER BY file_unique_id ASC
                    LIMIT %s
                    """,
                    (last_uid, int(batch_groups)),
                )
                uid_rows = await cur.fetchall()
            finally:
                await MySQLPool.release(conn, cur)

            if not uid_rows:
                print("ğŸ¯ [bid_thumbnail] no more t_update=4 groups. Done.", flush=True)
                break

            uids: List[str] = [r["file_unique_id"] for r in uid_rows if r.get("file_unique_id")]
            if not uids:
                break

            last_uid = uids[-1]
            total_groups += len(uids)

            # 2) æœ¬æ‰¹åœ¨åŒä¸€è¿æ¥å†…ï¼šå»ºä¸´æ—¶è¡¨ -> ç®— winners -> ä¸¤æ­¥ update
            conn, cur = await MySQLPool.get_conn_cursor()
            try:
                await conn.begin()

                # ä¸´æ—¶è¡¨ï¼šå­˜æœ¬æ‰¹æ¯ä¸ª file_unique_id çš„ winner_idï¼ˆbid_thumbnail_idï¼‰
                await cur.execute("DROP TEMPORARY TABLE IF EXISTS tmp_bt_winners")
                await cur.execute(
                    """
                    CREATE TEMPORARY TABLE tmp_bt_winners (
                        file_unique_id VARCHAR(50) NOT NULL,
                        winner_id INT UNSIGNED NOT NULL,
                        PRIMARY KEY (file_unique_id),
                        KEY idx_winner_id (winner_id)
                    ) ENGINE=MEMORY
                    """
                )

                # ä»¥ IN æ–¹å¼é™å®šæœ¬æ‰¹ file_unique_id
                placeholders = ",".join(["%s"] * len(uids))

                # è®¡ç®— winnerï¼š
                # - å…ˆæ‰¾æ¯ç»„ max(confirm_status)
                # - å†åœ¨ confirm_status=max çš„å€™é€‰é‡Œå– max(bid_thumbnail_id)
                sql_insert_winners = f"""
                    INSERT INTO tmp_bt_winners (file_unique_id, winner_id)
                    SELECT x.file_unique_id, MAX(bt.bid_thumbnail_id) AS winner_id
                    FROM (
                        SELECT file_unique_id, MAX(confirm_status) AS max_cs
                        FROM bid_thumbnail
                        WHERE t_update = 4
                          AND file_unique_id IN ({placeholders})
                        GROUP BY file_unique_id
                    ) x
                    JOIN bid_thumbnail bt
                      ON bt.file_unique_id = x.file_unique_id
                     AND bt.confirm_status = x.max_cs
                     AND bt.t_update = 4
                    GROUP BY x.file_unique_id
                """
                await cur.execute(sql_insert_winners, tuple(uids))

                # 2.1 winners -> t_update=5
                sql_set_winner_5 = """
                    UPDATE bid_thumbnail bt
                    JOIN tmp_bt_winners w
                      ON w.winner_id = bt.bid_thumbnail_id
                    SET bt.t_update = 5
                    WHERE bt.t_update = 4
                """
                await cur.execute(sql_set_winner_5)
                winners_set_5 = cur.rowcount or 0

                # 2.2 åŒç»„å…¶ä½™ä»ä¸º t_update=4 çš„ -> t_update=0
                # åªå¤„ç†æœ¬æ‰¹ uidsï¼ˆé¿å…æ³¢åŠä¸‹ä¸€æ‰¹ï¼‰
                sql_set_loser_0 = f"""
                    UPDATE bid_thumbnail bt
                    LEFT JOIN tmp_bt_winners w
                      ON w.file_unique_id = bt.file_unique_id
                     AND w.winner_id = bt.bid_thumbnail_id
                    SET bt.t_update = 0
                    WHERE bt.t_update = 4
                      AND bt.file_unique_id IN ({placeholders})
                      AND w.winner_id IS NULL
                """
                await cur.execute(sql_set_loser_0, tuple(uids))
                losers_set_0 = cur.rowcount or 0

                await conn.commit()

            except Exception:
                try:
                    await conn.rollback()
                except Exception:
                    pass
                raise
            finally:
                await MySQLPool.release(conn, cur)

            total_winners_set_5 += winners_set_5
            total_losers_set_0 += losers_set_0

            print(
                f"âœ… [bid_thumbnail] round={rounds} groups={len(uids)} "
                f"winners_to_5={winners_set_5} losers_to_0={losers_set_0} "
                f"grand_groups={total_groups} grand_winners={total_winners_set_5} grand_losers={total_losers_set_0}",
                flush=True,
            )

            if sleep_seconds and sleep_seconds > 0:
                await asyncio.sleep(float(sleep_seconds))

    except KeyboardInterrupt:
        print(
            f"â›” [bid_thumbnail] interrupted by user. rounds={rounds} "
            f"groups={total_groups} winners_to_5={total_winners_set_5} losers_to_0={total_losers_set_0}",
            flush=True,
        )

    result = {
        "rounds": rounds,
        "groups_processed": total_groups,
        "winners_set_to_5": total_winners_set_5,
        "losers_set_to_0": total_losers_set_0,
        "batch_groups": int(batch_groups),
        "sleep_seconds": float(sleep_seconds),
        "max_rounds": None if max_rounds is None else int(max_rounds),
    }
    print(f"ğŸ“Œ [bid_thumbnail] summary: {result}", flush=True)
    return result





async def apply_thumb_from_bid_thumbnail_t5_batched(
    batch_size: int = 500,
    sleep_seconds: float = 0.0,
    max_rounds: Optional[int] = None,
) -> Dict[str, Any]:
    """
    å¯¹ bid_thumbnail.t_update=5 æ‰§è¡Œå¯¹é½ï¼š
    - sc.source_id = bt.file_unique_id
    - è‹¥ bt.thumb_file_unique_id == sc.thumb_file_unique_id:
        bt.t_update = 1
      å¦åˆ™:
        bt.t_update = 6
        sc.thumb_file_unique_id = bt.thumb_file_unique_id
        sora_media.thumb_file_id = NULL WHERE sora_media.content_id = sc.id

    è¯´æ˜ï¼š
    - bid_thumbnail(MyISAM) æ— äº‹åŠ¡ï¼›sora_content/sora_media(InnoDB) æœ‰äº‹åŠ¡
    - æœ¬å®ç°ä»¥â€œå°æ‰¹æ¬¡ + InnoDB äº‹åŠ¡â€é™ä½ä¸ä¸€è‡´çª—å£
    """
    await MySQLPool.init_pool()
    await MySQLPool.ensure_pool()

    rounds = 0
    total_scanned = 0
    total_bt_to_1 = 0
    total_bt_to_6 = 0
    total_sc_thumb_updated = 0
    total_sm_thumb_nulled = 0

    print(
        "[t5->(1/6)] start: batch_size=%s sleep=%s max_rounds=%s"
        % (batch_size, sleep_seconds, max_rounds),
        flush=True,
    )

    try:
        while True:
            rounds += 1
            if max_rounds is not None and rounds > int(max_rounds):
                print("ğŸ›‘ Reached max_rounds=%s. Stop." % max_rounds, flush=True)
                break

            # 1) æ‹‰ä¸€æ‰¹éœ€è¦å¤„ç†çš„è®°å½•
            conn, cur = await MySQLPool.get_conn_cursor()
            try:
                await cur.execute(
                    """
                    SELECT
                        bt.bid_thumbnail_id AS bt_id,
                        bt.file_unique_id AS file_unique_id,
                        bt.thumb_file_unique_id AS bt_thumb_uid,
                        sc.id AS content_id,
                        sc.thumb_file_unique_id AS sc_thumb_uid
                    FROM bid_thumbnail bt
                    JOIN sora_content sc
                      ON sc.source_id = bt.file_unique_id
                    WHERE bt.t_update = 5
                    ORDER BY bt.bid_thumbnail_id ASC
                    LIMIT %s
                    """,
                    (int(batch_size),),
                )
                rows = await cur.fetchall()
            finally:
                await MySQLPool.release(conn, cur)

            if not rows:
                print("ğŸ¯ [t5->(1/6)] no more rows. Done.", flush=True)
                break

            total_scanned += len(rows)

            equal_bt_ids: List[int] = []
            # (bt_id, content_id, new_thumb_uid)
            mismatch_items: List[Tuple[int, int, Optional[str]]] = []

            for r in rows:
                bt_id = int(r["bt_id"])
                content_id = int(r["content_id"])
                bt_thumb_uid = r.get("bt_thumb_uid")  # Optional[str]
                sc_thumb_uid = r.get("sc_thumb_uid")  # Optional[str]

                if bt_thumb_uid == sc_thumb_uid:
                    equal_bt_ids.append(bt_id)
                else:
                    mismatch_items.append((bt_id, content_id, bt_thumb_uid))

            # 2) æ‰§è¡Œæ›´æ–°
            conn, cur = await MySQLPool.get_conn_cursor()
            try:
                # 2.1 ç›¸ç­‰ï¼šbt.t_update = 1
                bt_to_1 = 0
                if equal_bt_ids:
                    placeholders = ",".join(["%s"] * len(equal_bt_ids))
                    await cur.execute(
                        """
                        UPDATE bid_thumbnail
                        SET t_update = 1
                        WHERE t_update = 5
                          AND bid_thumbnail_id IN (%s)
                        """ % placeholders,
                        tuple(equal_bt_ids),
                    )
                    bt_to_1 = cur.rowcount or 0

                # 2.2 ä¸ç­‰ï¼šbt.t_update = 6ï¼ˆMyISAMï¼‰
                bt_to_6 = 0
                sc_updated = 0
                sm_nulled = 0

                if mismatch_items:
                    mismatch_bt_ids = [x[0] for x in mismatch_items]
                    mismatch_content_ids = [x[1] for x in mismatch_items]

                    placeholders = ",".join(["%s"] * len(mismatch_bt_ids))
                    await cur.execute(
                        """
                        UPDATE bid_thumbnail
                        SET t_update = 6
                        WHERE t_update = 5
                          AND bid_thumbnail_id IN (%s)
                        """ % placeholders,
                        tuple(mismatch_bt_ids),
                    )
                    bt_to_6 = cur.rowcount or 0

                    # 2.3 InnoDB äº‹åŠ¡ï¼šæ›´æ–° sora_content + sora_media
                    await conn.begin()
                    try:
                        # 2.3.1 æ›´æ–° sora_content.thumb_file_unique_id
                        # executemany çš„ rowcount åœ¨ä¸åŒé©±åŠ¨/ç‰ˆæœ¬ä¸‹å¯èƒ½ä¸å¯é ï¼Œæ‰€ä»¥è¿™é‡Œä»¥â€œæ‰§è¡ŒæˆåŠŸâ€ä¸ºä¸»ã€‚
                        payload_sc = []
                        for _, content_id, new_thumb_uid in mismatch_items:
                            payload_sc.append((new_thumb_uid, int(content_id)))

                        await cur.executemany(
                            """
                            UPDATE sora_content
                            SET thumb_file_unique_id = %s
                            WHERE id = %s
                            """,
                            payload_sc,
                        )
                        sc_updated = cur.rowcount or 0

                        # 2.3.2 æ¸…ç©º sora_media.thumb_file_idï¼ˆæŒ‰ content_id æ‰¹é‡ï¼‰
                        placeholders = ",".join(["%s"] * len(mismatch_content_ids))
                        await cur.execute(
                            """
                            UPDATE sora_media
                            SET thumb_file_id = NULL
                            WHERE content_id IN (%s)
                            """ % placeholders,
                            tuple(mismatch_content_ids),
                        )
                        sm_nulled = cur.rowcount or 0

                        await conn.commit()
                    except Exception:
                        try:
                            await conn.rollback()
                        except Exception:
                            pass
                        raise

                total_bt_to_1 += bt_to_1
                total_bt_to_6 += bt_to_6
                total_sc_thumb_updated += sc_updated
                total_sm_thumb_nulled += sm_nulled

            finally:
                await MySQLPool.release(conn, cur)

            print(
                "âœ… [t5->(1/6)] round=%s scanned=%s "
                "bt_to_1=%s bt_to_6=%s sc_updated=%s sm_nulled=%s total_scanned=%s"
                % (
                    rounds,
                    len(rows),
                    bt_to_1,
                    bt_to_6,
                    total_sc_thumb_updated,
                    total_sm_thumb_nulled,
                    total_scanned,
                ),
                flush=True,
            )

            if sleep_seconds and sleep_seconds > 0:
                await asyncio.sleep(float(sleep_seconds))

    except KeyboardInterrupt:
        print(
            "â›” [t5->(1/6)] interrupted. rounds=%s scanned=%s bt_to_1=%s bt_to_6=%s sc_updated=%s sm_nulled=%s"
            % (
                rounds,
                total_scanned,
                total_bt_to_1,
                total_bt_to_6,
                total_sc_thumb_updated,
                total_sm_thumb_nulled,
            ),
            flush=True,
        )

    result = {
        "rounds": rounds,
        "scanned": total_scanned,
        "bt_set_to_1": total_bt_to_1,
        "bt_set_to_6": total_bt_to_6,
        "sora_content_thumb_updated": total_sc_thumb_updated,
        "sora_media_thumb_file_id_nulled": total_sm_thumb_nulled,
        "batch_size": int(batch_size),
        "sleep_seconds": float(sleep_seconds),
        "max_rounds": None if max_rounds is None else int(max_rounds),
    }
    print("ğŸ“Œ [t5->(1/6)] summary: %s" % result, flush=True)
    return result



async def main():
    try:
        await sync()
    finally:
        # å…ˆå…³ MySQLï¼Œå†å…³ PGï¼ˆé¡ºåºä¸æ˜¯å…³é”®ï¼Œä½†è¦ç¡®ä¿éƒ½å…³ï¼‰
        try:
            await MySQLPool.close()
        except Exception as e:
            print(f"âš ï¸ MySQLPool.close failed: {e}", flush=True)

        try:
            await PGPool.close()   # ä½  lz_pgsql.PGPool åº”è¯¥ä¹Ÿæœ‰ close()/wait_closed()
        except Exception as e:
            print(f"âš ï¸ PGPool.close failed: {e}", flush=True)


if __name__ == "__main__":
    asyncio.run(main())
